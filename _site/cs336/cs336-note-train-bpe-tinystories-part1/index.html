<!DOCTYPE html>
<html lang="en"><head>
  <link rel="shortcut icon" type="image/png" href="/assets/favicon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Study Notes: Stanford CS336 Language Modeling from Scratch [3a] - Building BPE Tokenizer (Part 1) | ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [3a] - Building BPE Tokenizer (Part 1)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development." />
<meta property="og:description" content="A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development." />
<link rel="canonical" href="http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part1/" />
<meta property="og:url" content="http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part1/" />
<meta property="og:site_name" content="ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-26T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [3a] - Building BPE Tokenizer (Part 1)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-26T00:00:00-07:00","datePublished":"2025-07-26T00:00:00-07:00","description":"A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development.","headline":"Study Notes: Stanford CS336 Language Modeling from Scratch [3a] - Building BPE Tokenizer (Part 1)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part1/"},"url":"http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part1/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/chinese-online-content-for-llm/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/chinese-online-content-for-llm/feed.xml" title="ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±" /><link rel="stylesheet" href="/chinese-online-content-for-llm/assets/css/dark-mode.css">
<script src="/chinese-online-content-for-llm/assets/js/theme-toggle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/chinese-online-content-for-llm/">ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/chinese-online-content-for-llm/cs336/">ğŸ“š Stanford CS336</a><a class="page-link" href="/chinese-online-content-for-llm/career/">ğŸŒ± Career &amp; Growth</a><a class="page-link" href="/chinese-online-content-for-llm/ai-insights/">ğŸ§¬ AI Insights</a><a class="page-link" href="/chinese-online-content-for-llm/about/">å…³äºæœ¬ç«™</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Study Notes: Stanford CS336 Language Modeling from Scratch [3a] - Building BPE Tokenizer (Part 1)</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-07-26T00:00:00-07:00" itemprop="datePublished">
        Jul 26, 2025
      </time>â€¢ 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <style>
  .xiaohongshu-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    color: #ff2442; /* å°çº¢ä¹¦ä¸»è‰² */
    text-decoration: none;
    font-weight: bold;
    font-size: 14px;
  }
  .xiaohongshu-link:hover {
    text-decoration: underline;
  }
  .xiaohongshu-logo {
    width: 18px;
    height: 18px;
    border-radius: 4px;
  }
</style>

<div style="padding:12px;border:1px solid #eee;border-radius:8px;display:inline-block;margin-bottom:20px;">
  <strong>å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</strong><br />
  <p style="margin:4px 0;">
    å°çº¢ä¹¦å·ï¼š
    <a class="xiaohongshu-link" href="https://www.xiaohongshu.com/user/profile/5b2c5758e8ac2b08bf20e38d" target="_blank">
      <img class="xiaohongshu-logo" src="https://static.cdnlogo.com/logos/r/77/rednote-xiaohongshu.svg" alt="å°çº¢ä¹¦ logo" />
      119826921
    </a>
  </p>
  IPå±åœ°ï¼šç¾å›½
</div>

<h1 id="building-a-bpe-tokenizer-from-scratch-train-the-tokenizer-using-tinystories-dataset-part-1">Building a BPE Tokenizer from Scratch: Train the Tokenizer using TinyStories Dataset (Part 1)</h1>

<h1 id="ä»é›¶å¼€å§‹æ„å»ºbpeåˆ†è¯å™¨ä½¿ç”¨tinystoriesæ•°æ®é›†è®­ç»ƒåˆ†è¯å™¨ç¬¬1éƒ¨åˆ†">ä»é›¶å¼€å§‹æ„å»ºBPEåˆ†è¯å™¨ï¼šä½¿ç”¨TinyStoriesæ•°æ®é›†è®­ç»ƒåˆ†è¯å™¨ï¼ˆç¬¬1éƒ¨åˆ†ï¼‰</h1>

<p>Ever wondered how modern language models like GPT break down text into tokens? In this note, I will share how to build a Byte Pair Encoding (BPE) tokenizer from scratch and train it on the <a href="https://arxiv.org/abs/2305.07759">TinyStories Dataset</a>. We will see how BPE achieves impressive compression ratios.</p>

<p>ä½ æ˜¯å¦å¥½å¥‡è¿‡åƒGPTè¿™æ ·çš„ç°ä»£è¯­è¨€æ¨¡å‹æ˜¯å¦‚ä½•å°†æ–‡æœ¬åˆ†è§£ä¸ºè¯å…ƒï¼ˆtokensï¼‰çš„ï¼Ÿåœ¨è¿™ç¯‡ç¬”è®°ä¸­ï¼Œæˆ‘å°†åˆ†äº«å¦‚ä½•ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰åˆ†è¯å™¨ï¼Œå¹¶åœ¨<a href="https://arxiv.org/abs/2305.07759">TinyStoriesæ•°æ®é›†</a>ä¸Šè¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬å°†çœ‹åˆ°BPEå¦‚ä½•å®ç°ä»¤äººå°è±¡æ·±åˆ»çš„å‹ç¼©æ¯”ã€‚</p>

<h2 id="what-is-bpe-tokenization">What is BPE Tokenization?</h2>

<h2 id="ä»€ä¹ˆæ˜¯bpeåˆ†è¯">ä»€ä¹ˆæ˜¯BPEåˆ†è¯ï¼Ÿ</h2>

<p>Byte Pair Encoding (BPE) is a compression algorithm thatâ€™s become the backbone of modern tokenization. Hereâ€™s how it works:</p>

<p>å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰æ˜¯ä¸€ç§å‹ç¼©ç®—æ³•ï¼Œå·²æˆä¸ºç°ä»£åˆ†è¯æŠ€æœ¯çš„æ”¯æŸ±ã€‚å®ƒçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š</p>

<ol>
  <li><strong>Start with bytes</strong>: Every character becomes its byte representation (0-255)</li>
  <li><strong>Find frequent pairs</strong>: Look for the most common pair of adjacent tokens</li>
  <li>
    <p><strong>Merge and repeat</strong>: Replace the most frequent pair with a new token, then repeat</p>
  </li>
  <li><strong>ä»å­—èŠ‚å¼€å§‹</strong>ï¼šæ¯ä¸ªå­—ç¬¦éƒ½å˜æˆå…¶å­—èŠ‚è¡¨ç¤ºï¼ˆ0-255ï¼‰</li>
  <li><strong>æŸ¥æ‰¾é¢‘ç¹é…å¯¹</strong>ï¼šå¯»æ‰¾æœ€å¸¸è§çš„ç›¸é‚»è¯å…ƒå¯¹</li>
  <li><strong>åˆå¹¶å¹¶é‡å¤</strong>ï¼šç”¨æ–°è¯å…ƒæ›¿æ¢æœ€é¢‘ç¹çš„é…å¯¹ï¼Œç„¶åé‡å¤æ­¤è¿‡ç¨‹</li>
</ol>

<h3 id="a-simple-example">A Simple Example</h3>

<h3 id="ä¸€ä¸ªç®€å•çš„ä¾‹å­">ä¸€ä¸ªç®€å•çš„ä¾‹å­</h3>

<p>Letâ€™s say we have the word â€œhelloâ€ appearing many times in our text:</p>
<ul>
  <li>Initially: <code class="language-plaintext highlighter-rouge">h-e-l-l-o</code> (5 tokens)</li>
  <li>If â€œl-lâ€ is the most frequent pair, merge it: <code class="language-plaintext highlighter-rouge">h-e-ll-o</code> (4 tokens)</li>
  <li>If â€œe-llâ€ becomes frequent, merge it: <code class="language-plaintext highlighter-rouge">h-ell-o</code> (3 tokens)</li>
</ul>

<p>å‡è®¾æˆ‘ä»¬çš„æ–‡æœ¬ä¸­å¤šæ¬¡å‡ºç°å•è¯â€helloâ€ï¼š</p>
<ul>
  <li>åˆå§‹çŠ¶æ€ï¼š<code class="language-plaintext highlighter-rouge">h-e-l-l-o</code>ï¼ˆ5ä¸ªè¯å…ƒï¼‰</li>
  <li>å¦‚æœâ€l-lâ€æ˜¯æœ€é¢‘ç¹çš„é…å¯¹ï¼Œåˆ™åˆå¹¶å®ƒï¼š<code class="language-plaintext highlighter-rouge">h-e-ll-o</code>ï¼ˆ4ä¸ªè¯å…ƒï¼‰</li>
  <li>å¦‚æœâ€e-llâ€å˜å¾—é¢‘ç¹ï¼Œåˆ™åˆå¹¶å®ƒï¼š<code class="language-plaintext highlighter-rouge">h-ell-o</code>ï¼ˆ3ä¸ªè¯å…ƒï¼‰</li>
</ul>

<p>This process creates a vocabulary that efficiently represents common patterns in your text. Check out <a href="https://bearbearyu1223.github.io/cs336/2025/07/22/cs336-note-simple-bpe.html">my previous post</a> for a brief introduction.</p>

<p>è¿™ä¸ªè¿‡ç¨‹åˆ›å»ºäº†ä¸€ä¸ªè¯æ±‡è¡¨ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°è¡¨ç¤ºæ–‡æœ¬ä¸­çš„å¸¸è§æ¨¡å¼ã€‚æŸ¥çœ‹<a href="https://bearbearyu1223.github.io/cs336/2025/07/22/cs336-note-simple-bpe.html">æˆ‘ä¹‹å‰çš„æ–‡ç« </a>è·å–ç®€è¦ä»‹ç»ã€‚</p>

<h2 id="the-tinystories-dataset">The TinyStories Dataset</h2>

<h2 id="tinystoriesæ•°æ®é›†">TinyStoriesæ•°æ®é›†</h2>

<p>Weâ€™ll train our tokenizer on <a href="https://arxiv.org/abs/2305.07759">TinyStories</a>, a fascinating dataset of short stories written using only words that 3-4 year olds typically understand. These stories were generated by GPT-3.5 and GPT-4, making them perfect for experimenting with tokenization.</p>

<p>æˆ‘ä»¬å°†åœ¨<a href="https://arxiv.org/abs/2305.07759">TinyStories</a>æ•°æ®é›†ä¸Šè®­ç»ƒåˆ†è¯å™¨ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼•äººå…¥èƒœçš„çŸ­ç¯‡æ•…äº‹æ•°æ®é›†ï¼Œä»…ä½¿ç”¨3-4å²å„¿ç«¥é€šå¸¸èƒ½ç†è§£çš„è¯æ±‡ç¼–å†™ã€‚è¿™äº›æ•…äº‹ç”±GPT-3.5å’ŒGPT-4ç”Ÿæˆï¼Œä½¿å®ƒä»¬æˆä¸ºåˆ†è¯å®éªŒçš„å®Œç¾é€‰æ‹©ã€‚</p>

<h3 id="downloading-the-data">Downloading the Data</h3>

<h3 id="ä¸‹è½½æ•°æ®">ä¸‹è½½æ•°æ®</h3>

<p>First, letâ€™s download the TinyStories froom Huggingface:</p>

<p>é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»Huggingfaceä¸‹è½½TinyStoriesæ•°æ®é›†ï¼š</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">mkdir</span> <span class="o">-</span><span class="n">p</span> <span class="n">data</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">data</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">roneneldan</span><span class="o">/</span><span class="n">TinyStories</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">TinyStoriesV2</span><span class="o">-</span><span class="n">GPT4</span><span class="o">-</span><span class="n">train</span><span class="p">.</span><span class="n">txt</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">roneneldan</span><span class="o">/</span><span class="n">TinyStories</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">TinyStoriesV2</span><span class="o">-</span><span class="n">GPT4</span><span class="o">-</span><span class="n">valid</span><span class="p">.</span><span class="n">txt</span>

<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">stanford</span><span class="o">-</span><span class="n">cs336</span><span class="o">/</span><span class="n">owt</span><span class="o">-</span><span class="n">sample</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">owt_train</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">gunzip</span> <span class="n">owt_train</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="p">.</span><span class="n">co</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">stanford</span><span class="o">-</span><span class="n">cs336</span><span class="o">/</span><span class="n">owt</span><span class="o">-</span><span class="n">sample</span><span class="o">/</span><span class="n">resolve</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">owt_valid</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>
<span class="err">!</span><span class="n">gunzip</span> <span class="n">owt_valid</span><span class="p">.</span><span class="n">txt</span><span class="p">.</span><span class="n">gz</span>

<span class="err">!</span><span class="n">cd</span> <span class="p">..</span>
</code></pre></div></div>

<h2 id="challenge-parallelizing-pre-tokenization">Challenge: Parallelizing Pre-tokenization</h2>

<h2 id="æŒ‘æˆ˜å¹¶è¡ŒåŒ–é¢„åˆ†è¯">æŒ‘æˆ˜ï¼šå¹¶è¡ŒåŒ–é¢„åˆ†è¯</h2>

<p>The TinyStories dataset is big (over 2GB), which presents a challenge for tokenizer training. We need to:</p>
<ol>
  <li>Process the file in parallel for speed</li>
  <li>Ensure we donâ€™t split tokens incorrectly at chunk boundaries</li>
</ol>

<p>TinyStoriesæ•°æ®é›†å¾ˆå¤§ï¼ˆè¶…è¿‡2GBï¼‰ï¼Œè¿™ç»™åˆ†è¯å™¨è®­ç»ƒå¸¦æ¥äº†æŒ‘æˆ˜ã€‚æˆ‘ä»¬éœ€è¦ï¼š</p>
<ol>
  <li>å¹¶è¡Œå¤„ç†æ–‡ä»¶ä»¥æé«˜é€Ÿåº¦</li>
  <li>ç¡®ä¿åœ¨å—è¾¹ç•Œå¤„ä¸ä¼šé”™è¯¯åœ°åˆ†å‰²è¯å…ƒ</li>
</ol>

<h3 id="solution-smart-chunking-with-special-tokens">Solution: Smart Chunking with Special Tokens</h3>

<h3 id="è§£å†³æ–¹æ¡ˆä½¿ç”¨ç‰¹æ®Šæ ‡è®°è¿›è¡Œæ™ºèƒ½åˆ†å—">è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç‰¹æ®Šæ ‡è®°è¿›è¡Œæ™ºèƒ½åˆ†å—</h3>

<p>Our solution uses special tokens (like <code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>) as natural boundaries for splitting the file.</p>

<p>æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚<code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>ï¼‰ä½œä¸ºåˆ†å‰²æ–‡ä»¶çš„è‡ªç„¶è¾¹ç•Œã€‚</p>

<p><strong>Simple Example</strong>: Letâ€™s say we have a text file containing: â€œHello<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>World<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>How<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>Are<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>Youâ€, special split token is <code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>, and we want to divide the text into 3 chunks.</p>

<p><strong>ç®€å•ç¤ºä¾‹</strong>ï¼šå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œå†…å®¹ä¸ºï¼šâ€Hello<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>World<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>How<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>Are<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>Youâ€ï¼Œç‰¹æ®Šåˆ†å‰²æ ‡è®°æ˜¯<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>ï¼Œæˆ‘ä»¬æƒ³å°†æ–‡æœ¬åˆ†æˆ3ä¸ªå—ã€‚</p>

<p>Hereâ€™s one implementation for intelligent file chunking as shared in the <a href="https://github.com/stanford-cs336/assignment1-basics/blob/main/cs336_basics/pretokenization_example.py">cs336 lecture notes</a>:</p>

<p>ä»¥ä¸‹æ˜¯<a href="https://github.com/stanford-cs336/assignment1-basics/blob/main/cs336_basics/pretokenization_example.py">cs336è¯¾ç¨‹ç¬”è®°</a>ä¸­åˆ†äº«çš„æ™ºèƒ½æ–‡ä»¶åˆ†å—çš„ä¸€ç§å®ç°ï¼š</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">BinaryIO</span>

<span class="k">def</span> <span class="nf">find_chunk_boundaries</span><span class="p">(</span> <span class="nb">file</span><span class="p">:</span> <span class="n">BinaryIO</span><span class="p">,</span>
      <span class="n">desired_num_chunks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
      <span class="n">split_special_token</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span><span class="o">-&gt;</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
  <span class="s">"""
  Chunk the file into parts that can be counted independently.
  May return fewer chunks if the boundaries end up overlapping.
  """</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">split_special_token</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">),(</span>
      <span class="s">"Must represent special token as a bytestring"</span>
  <span class="p">)</span>

  <span class="c1"># Get total file size in bytes
</span>  <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">SEEK_END</span><span class="p">)</span>
  <span class="n">file_size</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">tell</span><span class="p">()</span>
  <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">desired_num_chunks</span>

  <span class="c1"># Initial guesses for chunk boundary locations, uniformly spaced
</span>  <span class="c1"># Chunks start on previous index, don't include last index
</span>  <span class="n">chunk_boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">desired_num_chunks</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial guess of the chunk boundaries: </span><span class="si">{</span><span class="n">chunk_boundaries</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
  <span class="n">chunk_boundaries</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>

  <span class="n">mini_chunk_size</span> <span class="o">=</span> <span class="mi">4096</span>  <span class="c1"># Read ahead by 4k bytes at a time
</span>
  <span class="k">for</span> <span class="n">bi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk_boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">initial_position</span> <span class="o">=</span> <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span>
      <span class="nb">file</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">initial_position</span><span class="p">)</span>  <span class="c1"># Start at boundary guess
</span>      <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
          <span class="n">mini_chunk</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">mini_chunk_size</span><span class="p">)</span>  <span class="c1"># Read a mini chunk
</span>
          <span class="c1"># If EOF, this boundary should be at the end of the file
</span>          <span class="k">if</span> <span class="n">mini_chunk</span> <span class="o">==</span> <span class="sa">b</span><span class="s">""</span><span class="p">:</span>
              <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>
              <span class="k">break</span>

          <span class="c1"># Find the special token in the mini chunk
</span>          <span class="n">found_at</span> <span class="o">=</span> <span class="n">mini_chunk</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">split_special_token</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">found_at</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
              <span class="n">chunk_boundaries</span><span class="p">[</span><span class="n">bi</span><span class="p">]</span> <span class="o">=</span> <span class="n">initial_position</span> <span class="o">+</span> <span class="n">found_at</span>
              <span class="k">break</span>
          <span class="n">initial_position</span> <span class="o">+=</span> <span class="n">mini_chunk_size</span>

  <span class="c1"># Make sure all boundaries are unique, but might be fewer than desired_num_chunks
</span>  <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chunk_boundaries</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="testing-our-chunking-algorithm">Testing Our Chunking Algorithm</h3>

<h3 id="æµ‹è¯•æˆ‘ä»¬çš„åˆ†å—ç®—æ³•">æµ‹è¯•æˆ‘ä»¬çš„åˆ†å—ç®—æ³•</h3>

<p>Letâ€™s see how this works with a concrete example:</p>

<p>è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼š</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">io</span>
<span class="k">def</span> <span class="nf">demonstrate_chunk_boundaries</span><span class="p">():</span>
    <span class="s">"""Demonstrate how to use find_chunk_boundaries with a practical example."""</span>

    <span class="c1"># Create sample data - our example text
</span>    <span class="n">sample_text</span> <span class="o">=</span> <span class="s">"Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You"</span>
    <span class="n">sample_bytes</span> <span class="o">=</span> <span class="n">sample_text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"=== Original Data ==="</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Text: </span><span class="si">{</span><span class="n">sample_text</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Bytes: </span><span class="si">{</span><span class="n">sample_bytes</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">sample_bytes</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Create a file-like object from our sample data
</span>    <span class="n">file_obj</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">sample_bytes</span><span class="p">)</span>

    <span class="c1"># Define our split token
</span>    <span class="n">split_token</span> <span class="o">=</span> <span class="sa">b</span><span class="s">"&lt;SPLIT&gt;"</span>
    <span class="n">desired_chunks</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"=== Finding Chunk Boundaries ==="</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Desired number of chunks: </span><span class="si">{</span><span class="n">desired_chunks</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Split token: </span><span class="si">{</span><span class="n">split_token</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Find the chunk boundaries
</span>    <span class="n">boundaries</span> <span class="o">=</span> <span class="n">find_chunk_boundaries</span><span class="p">(</span><span class="n">file_obj</span><span class="p">,</span> <span class="n">desired_chunks</span><span class="p">,</span> <span class="n">split_token</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Final boundaries: </span><span class="si">{</span><span class="n">boundaries</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Number of chunks created: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="c1"># Demonstrate how to use the boundaries to read chunks
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"=== Reading Chunks ==="</span><span class="p">)</span>
    <span class="n">file_obj</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Reset file pointer
</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">end_pos</span> <span class="o">=</span> <span class="n">boundaries</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">end_pos</span> <span class="o">-</span> <span class="n">start_pos</span>

        <span class="c1"># Read the chunk
</span>        <span class="n">file_obj</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start_pos</span><span class="p">)</span>
        <span class="n">chunk_data</span> <span class="o">=</span> <span class="n">file_obj</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">)</span>
        <span class="n">chunk_text</span> <span class="o">=</span> <span class="n">chunk_data</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Chunk </span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Position: bytes </span><span class="si">{</span><span class="n">start_pos</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">end_pos</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Content: '</span><span class="si">{</span><span class="n">chunk_text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Raw bytes: </span><span class="si">{</span><span class="n">chunk_data</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">()</span>
</code></pre></div></div>

<p>Running this demonstration:</p>

<p>è¿è¡Œæ­¤æ¼”ç¤ºï¼š</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">demonstrate_chunk_boundaries</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Output:</strong></p>

<p><strong>è¾“å‡ºï¼š</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=== Original Data ===
Text: Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You
Bytes: b'Hello&lt;SPLIT&gt;World&lt;SPLIT&gt;How&lt;SPLIT&gt;Are&lt;SPLIT&gt;You'
Total size: 47 bytes

=== Finding Chunk Boundaries ===
Desired number of chunks: 3
Split token: b'&lt;SPLIT&gt;'

Initial guess of the chunk boundaries: [0, 15, 30, 45]
Final boundaries: [0, 17, 37, 47]
Number of chunks created: 3

=== Reading Chunks ===
Chunk 1:
  Position: bytes 0-16
  Size: 17 bytes
  Content: 'Hello&lt;SPLIT&gt;World'
  Raw bytes: b'Hello&lt;SPLIT&gt;World'

Chunk 2:
  Position: bytes 17-36
  Size: 20 bytes
  Content: '&lt;SPLIT&gt;How&lt;SPLIT&gt;Are'
  Raw bytes: b'&lt;SPLIT&gt;How&lt;SPLIT&gt;Are'

Chunk 3:
  Position: bytes 37-46
  Size: 10 bytes
  Content: '&lt;SPLIT&gt;You'
  Raw bytes: b'&lt;SPLIT&gt;You'
</code></pre></div></div>

<p>Notice how the algorithm automatically adjusted the boundaries to align with <code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code> tokens, ensuring clean chunk separation.</p>

<p>æ³¨æ„ç®—æ³•å¦‚ä½•è‡ªåŠ¨è°ƒæ•´è¾¹ç•Œä»¥ä¸<code class="language-plaintext highlighter-rouge">&lt;SPLIT&gt;</code>æ ‡è®°å¯¹é½ï¼Œç¡®ä¿å—çš„æ¸…æ™°åˆ†ç¦»ã€‚</p>

<h2 id="bpe-training-implementation">BPE Training Implementation</h2>

<h2 id="bpeè®­ç»ƒå®ç°">BPEè®­ç»ƒå®ç°</h2>

<p>Now implement the core BPE training algorithm. The implementation shared here handles parallel processing, special tokens, and efficient pair counting.</p>

<p>ç°åœ¨å®ç°æ ¸å¿ƒçš„BPEè®­ç»ƒç®—æ³•ã€‚è¿™é‡Œåˆ†äº«çš„å®ç°å¤„ç†äº†å¹¶è¡Œå¤„ç†ã€ç‰¹æ®Šæ ‡è®°å’Œé«˜æ•ˆçš„é…å¯¹è®¡æ•°ã€‚</p>

<h3 id="core-training-function">Core Training Function</h3>

<h3 id="æ ¸å¿ƒè®­ç»ƒå‡½æ•°">æ ¸å¿ƒè®­ç»ƒå‡½æ•°</h3>

<p>Hereâ€™s is my complete BPE training implementation:</p>

<p>è¿™æ˜¯æˆ‘å®Œæ•´çš„BPEè®­ç»ƒå®ç°ï¼š</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="k">as</span> <span class="n">mp</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">BinaryIO</span>

<span class="c1"># Simplified GPT-2-style regex pattern for pre-tokenization (using standard re module)
</span><span class="n">GPT2_SPLIT_PATTERN</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"""'(?:[sdmt]|ll|ve|re)| ?[a-zA-ZÃ€-Ã¿]+| ?[0-9]+| ?[^\s\w]+|\s+(?!\S)|\s+"""</span>

<span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="s">"""Process a chunk of the file and return word counts."""</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">special_tokens</span> <span class="o">=</span> <span class="n">args</span>
    <span class="n">word_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

        <span class="c1"># Split on special tokens to prevent merging across boundaries
</span>        <span class="k">if</span> <span class="n">special_tokens</span><span class="p">:</span>
            <span class="n">pattern</span> <span class="o">=</span> <span class="s">'|'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">re</span><span class="p">.</span><span class="n">escape</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">)</span>
            <span class="n">text_segments</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="sa">f</span><span class="s">'(</span><span class="si">{</span><span class="n">pattern</span><span class="si">}</span><span class="s">)'</span><span class="p">,</span> <span class="n">chunk</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">text_segments</span> <span class="o">=</span> <span class="p">[</span><span class="n">chunk</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">text_segments</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">segment</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
                <span class="k">continue</span>  <span class="c1"># Skip special tokens during counting
</span>
            <span class="c1"># Apply GPT-2 regex pattern
</span>            <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">re</span><span class="p">.</span><span class="n">finditer</span><span class="p">(</span><span class="n">GPT2_SPLIT_PATTERN</span><span class="p">,</span> <span class="n">segment</span><span class="p">):</span>
                <span class="n">token_text</span> <span class="o">=</span> <span class="n">match</span><span class="p">.</span><span class="n">group</span><span class="p">()</span>
                <span class="n">token_bytes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token_text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
                <span class="n">word_counts</span><span class="p">[</span><span class="n">token_bytes</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">word_counts</span>


<span class="k">def</span> <span class="nf">train_bpe_tokenizer</span><span class="p">(</span><span class="n">input_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]]:</span>
    <span class="s">"""
    Train a byte-level Byte Pair Encoding (BPE) tokenizer from a text file.

    Args:
        input_path: Path to the input text file containing training data
        vocab_size: Maximum size of the final vocabulary (includes initial bytes + special tokens + merges)
        special_tokens: List of special token strings to include in vocabulary
        verbose: Whether to print training progress information

    Returns:
        vocab: Complete tokenizer vocabulary mapping token IDs to byte sequences
        merges: Ordered list of BPE merge operations performed during training
    """</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Initialize vocabulary with bytes 0-255
</span>    <span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">)}</span>
    <span class="n">next_id</span> <span class="o">=</span> <span class="mi">256</span>

    <span class="c1"># Add special tokens to vocabulary
</span>    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
        <span class="n">token_bytes</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
        <span class="n">vocab</span><span class="p">[</span><span class="n">next_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_bytes</span>
        <span class="n">next_id</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Step 1: Setting up parallel processing..."</span><span class="p">)</span>

    <span class="c1"># Get chunk boundaries for multiprocessing
</span>    <span class="n">num_processes</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">cpu_count</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Using </span><span class="si">{</span><span class="n">num_processes</span><span class="si">}</span><span class="s"> processes for parallel tokenization"</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">special_tokens</span><span class="p">:</span>
            <span class="c1"># Use first special token for chunking boundaries
</span>            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Finding chunk boundaries aligned with special token: </span><span class="si">{</span><span class="n">special_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="n">boundaries</span> <span class="o">=</span> <span class="n">find_chunk_boundaries</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">num_processes</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use simple chunking without special token alignment
</span>            <span class="n">f</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">SEEK_END</span><span class="p">)</span>
            <span class="n">file_size</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">tell</span><span class="p">()</span>
            <span class="n">chunk_size</span> <span class="o">=</span> <span class="n">file_size</span> <span class="o">//</span> <span class="n">num_processes</span>
            <span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">chunk_size</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_processes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">boundaries</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_size</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"File size: </span><span class="si">{</span><span class="n">file_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes, chunk size: </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> bytes"</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Created </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s"> chunks for processing"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Step 2: Pre-tokenizing text corpus..."</span><span class="p">)</span>

    <span class="c1"># Process chunks in parallel
</span>    <span class="n">chunk_args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boundaries</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">boundaries</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">chunk_args</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">special_tokens</span><span class="p">))</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">mp</span><span class="p">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
        <span class="n">chunk_results</span> <span class="o">=</span> <span class="n">pool</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">process_chunk</span><span class="p">,</span> <span class="n">chunk_args</span><span class="p">)</span>
    <span class="n">tokenization_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Pre-tokenization completed in </span><span class="si">{</span><span class="n">tokenization_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>

    <span class="c1"># Merge results from all chunks
</span>    <span class="n">word_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">chunk_result</span> <span class="ow">in</span> <span class="n">chunk_results</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">chunk_result</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="n">count</span>
            <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">count</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> unique word types"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total token count: </span><span class="si">{</span><span class="n">total_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Most common words:"</span><span class="p">)</span>
        <span class="n">sorted_words</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">word_bytes</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_words</span><span class="p">[:</span><span class="mi">5</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">word_str</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">. '</span><span class="si">{</span><span class="n">word_str</span><span class="si">}</span><span class="s">' -&gt; </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> times"</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">. </span><span class="si">{</span><span class="n">word_bytes</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> times"</span><span class="p">)</span>

    <span class="c1"># Convert to working format for BPE (list of byte values)
</span>    <span class="n">word_freq</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">word_bytes</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">word_tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">)</span>  <span class="c1"># Convert to list of ints
</span>        <span class="n">word_freq</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">word_tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">freq</span>

    <span class="n">merges</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pair_index</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Efficient indexing for pair counting
</span>
    <span class="k">def</span> <span class="nf">update_pair_index</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">pair_index</span><span class="p">):</span>
        <span class="s">"""Update the pair index for efficient counting."""</span>
        <span class="n">pair_index</span><span class="p">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pair</span> <span class="o">=</span> <span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">pair</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pair_index</span><span class="p">:</span>
                    <span class="n">pair_index</span><span class="p">[</span><span class="n">pair</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">pair_index</span><span class="p">[</span><span class="n">pair</span><span class="p">].</span><span class="n">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">freq</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">count_pairs</span><span class="p">(</span><span class="n">pair_index</span><span class="p">):</span>
        <span class="s">"""Count pair frequencies efficiently using the index."""</span>
        <span class="n">pair_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pair</span><span class="p">,</span> <span class="n">occurrences</span> <span class="ow">in</span> <span class="n">pair_index</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">total_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">freq</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">occurrences</span><span class="p">)</span>
            <span class="n">pair_counts</span><span class="p">[</span><span class="n">pair</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_count</span>
        <span class="k">return</span> <span class="n">pair_counts</span>

    <span class="c1"># BPE training loop
</span>    <span class="n">target_merges</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Step 3: Training BPE with </span><span class="si">{</span><span class="n">target_merges</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> merges..."</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s"> (256 bytes + </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)</span><span class="si">}</span><span class="s"> special tokens)"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="n">bpe_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">merge_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_merges</span><span class="p">):</span>
        <span class="n">merge_step_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Update pair index
</span>        <span class="n">update_pair_index</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">pair_index</span><span class="p">)</span>

        <span class="c1"># Count pairs efficiently
</span>        <span class="n">pair_counts</span> <span class="o">=</span> <span class="n">count_pairs</span><span class="p">(</span><span class="n">pair_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">pair_counts</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"No more pairs to merge at step </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">break</span>

        <span class="c1"># Find most frequent pair (with lexicographic tiebreaking)
</span>        <span class="n">best_pair</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">pair_counts</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">best_count</span> <span class="o">=</span> <span class="n">pair_counts</span><span class="p">[</span><span class="n">best_pair</span><span class="p">]</span>

        <span class="c1"># Create new token for merge
</span>        <span class="n">new_token_id</span> <span class="o">=</span> <span class="n">next_id</span>
        <span class="n">next_id</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Get the byte sequences for the tokens being merged
</span>        <span class="n">left_bytes</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">right_bytes</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="c1"># Record merge as byte sequences
</span>        <span class="n">merges</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">left_bytes</span><span class="p">,</span> <span class="n">right_bytes</span><span class="p">))</span>

        <span class="c1"># Update vocabulary - merge the two byte sequences
</span>        <span class="n">vocab</span><span class="p">[</span><span class="n">new_token_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span>

        <span class="c1"># Update word frequencies by applying merge
</span>        <span class="n">new_word_freq</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">best_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_token_id</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">new_word_tuple</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_word_tuple</span> <span class="ow">in</span> <span class="n">new_word_freq</span><span class="p">:</span>
                <span class="n">new_word_freq</span><span class="p">[</span><span class="n">new_word_tuple</span><span class="p">]</span> <span class="o">+=</span> <span class="n">freq</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_word_freq</span><span class="p">[</span><span class="n">new_word_tuple</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq</span>

        <span class="n">word_freq</span> <span class="o">=</span> <span class="n">new_word_freq</span>
        <span class="n">merge_step_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">merge_step_start</span>

        <span class="c1"># Progress logging
</span>        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">merge_num</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">or</span> <span class="p">(</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">left_str</span> <span class="o">=</span> <span class="n">left_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="n">right_str</span> <span class="o">=</span> <span class="n">right_bytes</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="n">merged_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span><span class="p">).</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'replace'</span><span class="p">)</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merge </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">target_merges</span><span class="si">}</span><span class="s">: "</span>
                          <span class="sa">f</span><span class="s">"'</span><span class="si">{</span><span class="n">left_str</span><span class="si">}</span><span class="s">' + '</span><span class="si">{</span><span class="n">right_str</span><span class="si">}</span><span class="s">' -&gt; '</span><span class="si">{</span><span class="n">merged_str</span><span class="si">}</span><span class="s">' "</span>
                          <span class="sa">f</span><span class="s">"(freq: </span><span class="si">{</span><span class="n">best_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">, time: </span><span class="si">{</span><span class="n">merge_step_time</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">s)"</span><span class="p">)</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merge </span><span class="si">{</span><span class="n">merge_num</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="mi">4</span><span class="n">d</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">target_merges</span><span class="si">}</span><span class="s">: "</span>
                          <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">left_bytes</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">right_bytes</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">left_bytes</span> <span class="o">+</span> <span class="n">right_bytes</span><span class="si">}</span><span class="s"> "</span>
                          <span class="sa">f</span><span class="s">"(freq: </span><span class="si">{</span><span class="n">best_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">, time: </span><span class="si">{</span><span class="n">merge_step_time</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">s)"</span><span class="p">)</span>

    <span class="n">bpe_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">bpe_start_time</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"BPE training completed in </span><span class="si">{</span><span class="n">bpe_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Final vocabulary size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Total merges performed: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="c1"># Show compression statistics
</span>        <span class="k">if</span> <span class="n">word_counts</span><span class="p">:</span>
            <span class="n">original_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">word_bytes</span><span class="p">))</span> <span class="k">for</span> <span class="n">word_bytes</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
            <span class="n">compressed_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
            <span class="n">compression_ratio</span> <span class="o">=</span> <span class="n">original_tokens</span> <span class="o">/</span> <span class="n">compressed_tokens</span> <span class="k">if</span> <span class="n">compressed_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Compression ratio: </span><span class="si">{</span><span class="n">compression_ratio</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">x (from </span><span class="si">{</span><span class="n">original_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">compressed_tokens</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> tokens)"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span>


<span class="k">def</span> <span class="nf">save_tokenizer</span><span class="p">(</span><span class="n">vocab</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="n">merges</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]],</span>
                  <span class="n">vocab_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">merges_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="s">"""Save vocabulary and merges to disk files."""</span>
    <span class="kn">import</span> <span class="nn">json</span>
    <span class="kn">import</span> <span class="nn">pickle</span>

    <span class="c1"># Save vocabulary
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="c1"># Save merges
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_path</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">merges</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_tokenizer</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">merges_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">bytes</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]]]:</span>
    <span class="s">"""Load vocabulary and merges from disk files."""</span>
    <span class="kn">import</span> <span class="nn">pickle</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">merges</span>
</code></pre></div></div>

<hr />

<p>Continue reading in <a href="/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part2/">Part 2</a> for training results and testing examples.</p>

<p>ç»§ç»­é˜…è¯»<a href="/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part2/">ç¬¬2éƒ¨åˆ†</a>ä»¥æŸ¥çœ‹è®­ç»ƒç»“æœå’Œæµ‹è¯•ç¤ºä¾‹ã€‚</p>

  </div><a class="u-url" href="/chinese-online-content-for-llm/cs336/cs336-note-train-bpe-tinystories-part1/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/chinese-online-content-for-llm/"></data>

  <div class="wrapper">
    <!-- Support Section -->
    <div class="footer-support-section">
      <h3>â˜• æ”¯æŒæˆ‘çš„åˆ›ä½œ Support My Work</h3>
      <p style="margin-bottom: 1em; opacity: 0.9;">å¦‚æœè¿™äº›å†…å®¹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿è¯·æˆ‘å–æ¯å’–å•¡ï¼<br>If you find my content helpful, consider buying me a coffee!</p>
      <div class="support-options">
        <a href="https://ko-fi.com/bearbearyu1223_go_irish" target="_blank" rel="noopener" class="support-btn buymeacoffee-btn">
          <span class="btn-icon">â˜•</span>
          <span class="btn-text">Buy Me a Coffee</span>
        </a>
      </div>
    </div>

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/chinese-online-content-for-llm/feed.xml">
            <svg class="svg-icon orange"><use xlink:href="/chinese-online-content-for-llm/assets/minima-social-icons.svg#rss"></use></svg><span>Subscribe</span>
          </a>
        </p>
        <p>A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development.
</p>
      </div>
      <div class="footer-col">
        <p>Â© 2025 ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</p>
      </div>
    </div>
  </div>

  <!-- Theme toggle button -->
  <button id="theme-toggle" aria-label="Toggle dark mode">ğŸŒ™</button>
</footer>

<style>
.footer-support-section {
  text-align: center;
  padding: 2em 0;
  margin-bottom: 2em;
  border-bottom: 1px solid var(--border-color);
}

.footer-support-section h3 {
  margin: 0 0 0.5em 0;
  color: var(--text-color);
}

.support-options {
  display: flex;
  gap: 1em;
  justify-content: center;
  flex-wrap: wrap;
}

.support-btn {
  display: inline-flex;
  align-items: center;
  gap: 0.5em;
  padding: 0.75em 1.5em;
  border: none;
  border-radius: 8px;
  font-size: 1em;
  font-weight: 600;
  text-decoration: none;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.support-btn:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(0,0,0,0.15);
}

.buymeacoffee-btn {
  background: #FFDD00;
  color: #000;
}

.buymeacoffee-btn:hover {
  background: #FFE633;
}

.btn-icon {
  font-size: 1.2em;
}

[data-theme="dark"] .footer-support-section {
  border-bottom-color: #444;
}

[data-theme="dark"] .support-btn {
  box-shadow: 0 2px 8px rgba(0,0,0,0.3);
}

[data-theme="dark"] .support-btn:hover {
  box-shadow: 0 4px 12px rgba(0,0,0,0.4);
}
</style>
<!-- Floating Support Button -->
<a href="https://ko-fi.com/bearbearyu1223_go_irish" target="_blank" rel="noopener" id="floating-support-btn" class="floating-support-btn" aria-label="Support this site">
  <span class="support-heart">â¤ï¸</span>
  <span class="support-text">Support</span>
</a>

<!-- Support Modal -->
<div id="support-modal" class="support-modal" onclick="if(event.target === this) this.style.display='none'">
  <div class="support-modal-content">
    <button class="modal-close" onclick="document.getElementById('support-modal').style.display='none'" aria-label="Close modal">&times;</button>

    <h2 style="text-align: center; margin-top: 0;">â˜• æ”¯æŒæˆ‘çš„åˆ›ä½œ</h2>
    <p style="text-align: center; color: #666; margin-bottom: 2em;">
      å¦‚æœè¿™äº›å†…å®¹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿æ”¯æŒæˆ‘ç»§ç»­åˆ›ä½œï¼<br>
      <small>If you find my content helpful, please consider supporting my work!</small>
    </p>

    <div class="support-methods">
      <!-- Buy Me a Coffee -->
      <div class="support-method">
        <div class="method-icon" style="background: #FFDD00;">â˜•</div>
        <h3>Buy Me a Coffee</h3>
        <p>One-time support with PayPal, Card, etc.</p>
        <a href="https://buymeacoffee.com/YOUR_USERNAME" target="_blank" rel="noopener" class="method-btn" style="background: #FFDD00; color: #000;">
          Support on Buy Me a Coffee
        </a>
      </div>

      <!-- Ko-fi -->
      <div class="support-method">
        <div class="method-icon" style="background: #13C3FF; color: white;">ğŸ’™</div>
        <h3>Ko-fi</h3>
        <p>Zero fees! Support with PayPal or Card</p>
        <a href="https://ko-fi.com/bearbearyu1223_go_irish" target="_blank" rel="noopener" class="method-btn" style="background: #13C3FF; color: white;">
          Support on Ko-fi
        </a>
      </div>

      <!-- GitHub Sponsors (Optional) -->
      <div class="support-method">
        <div class="method-icon" style="background: #24292e; color: white;">â­</div>
        <h3>GitHub Sponsors</h3>
        <p>Monthly sponsorship for tech creators</p>
        <a href="https://github.com/sponsors/YOUR_USERNAME" target="_blank" rel="noopener" class="method-btn" style="background: #24292e; color: white;">
          Sponsor on GitHub
        </a>
      </div>
    </div>

    <p style="text-align: center; margin-top: 2em; color: #888; font-size: 0.9em;">
      æ„Ÿè°¢ä½ çš„æ”¯æŒï¼ä½ çš„æ¯ä¸€ä»½å¿ƒæ„éƒ½æ˜¯æˆ‘æŒç»­åˆ›ä½œçš„åŠ¨åŠ› â¤ï¸<br>
      <small>Thank you for your support! Every contribution motivates me to create more content.</small>
    </p>
  </div>
</div>

<style>
/* Floating Support Button */
.floating-support-btn {
  position: fixed;
  bottom: 30px;
  right: 30px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border: none;
  border-radius: 50px;
  padding: 12px 24px;
  font-size: 16px;
  font-weight: 600;
  cursor: pointer;
  box-shadow: 0 4px 16px rgba(102, 126, 234, 0.4);
  z-index: 999;
  display: flex;
  align-items: center;
  gap: 8px;
  transition: all 0.3s ease;
  text-decoration: none;
}

.floating-support-btn:hover {
  transform: translateY(-3px);
  box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
  color: white;
  text-decoration: none;
}

.support-heart {
  font-size: 1.2em;
  animation: heartbeat 1.5s ease-in-out infinite;
}

@keyframes heartbeat {
  0%, 100% { transform: scale(1); }
  25% { transform: scale(1.1); }
  50% { transform: scale(1); }
}

/* Support Modal */
.support-modal {
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0, 0, 0, 0.7);
  z-index: 1000;
  justify-content: center;
  align-items: center;
  padding: 20px;
  overflow-y: auto;
}

.support-modal-content {
  background: var(--bg-color);
  border-radius: 16px;
  padding: 2em;
  max-width: 900px;
  width: 100%;
  position: relative;
  box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
  max-height: 90vh;
  overflow-y: auto;
}

.modal-close {
  position: absolute;
  top: 15px;
  right: 15px;
  background: none;
  border: none;
  font-size: 2em;
  color: var(--text-color);
  cursor: pointer;
  line-height: 1;
  padding: 0;
  width: 40px;
  height: 40px;
  display: flex;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  transition: background 0.3s ease;
}

.modal-close:hover {
  background: rgba(0, 0, 0, 0.1);
}

.support-methods {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 1.5em;
  margin: 2em 0;
}

.support-method {
  border: 2px solid var(--border-color);
  border-radius: 12px;
  padding: 1.5em;
  text-align: center;
  background: var(--bg-color);
  transition: all 0.3s ease;
}

.support-method:hover {
  transform: translateY(-5px);
  box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1);
  border-color: #667eea;
}

.method-icon {
  width: 60px;
  height: 60px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 2em;
  margin: 0 auto 1em auto;
}

.support-method h3 {
  margin: 0.5em 0;
  color: var(--text-color);
}

.support-method p {
  color: #666;
  font-size: 0.9em;
  margin: 0.5em 0 1em 0;
  min-height: 2.5em;
}

.method-btn {
  display: inline-block;
  padding: 0.75em 1.5em;
  border-radius: 8px;
  text-decoration: none;
  font-weight: 600;
  transition: all 0.3s ease;
}

.method-btn:hover {
  transform: scale(1.05);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}

/* Dark mode adjustments */
[data-theme="dark"] .modal-close:hover {
  background: rgba(255, 255, 255, 0.1);
}

[data-theme="dark"] .support-method {
  background: #1a1a1a;
}

[data-theme="dark"] .support-method p {
  color: #a0aec0;
}

/* Responsive design */
@media (max-width: 768px) {
  .floating-support-btn {
    bottom: 20px;
    right: 20px;
    padding: 10px 20px;
    font-size: 14px;
  }

  .support-modal-content {
    padding: 1.5em;
    margin: 10px;
  }

  .support-methods {
    grid-template-columns: 1fr;
  }
}

@media (max-width: 480px) {
  .floating-support-btn {
    bottom: 15px;
    right: 15px;
    padding: 8px 16px;
    font-size: 13px;
  }

  .support-text {
    display: none;
  }
}
</style>
</body>

</html>
