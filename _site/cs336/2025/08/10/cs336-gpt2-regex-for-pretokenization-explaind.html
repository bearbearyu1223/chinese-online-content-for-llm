<!DOCTYPE html>
<html lang="en"><head>
  <link rel="shortcut icon" type="image/png" href="/assets/favicon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Study Notes: Stanford CS336 Language Modeling from Scratch [4] | üçí Han‚Äôs Generative AI Quest</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [4]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Demystifying GPT-2‚Äôs Pre-Tokenization: How One Regex Pattern Handles the World‚Äôs Languages" />
<meta property="og:description" content="Demystifying GPT-2‚Äôs Pre-Tokenization: How One Regex Pattern Handles the World‚Äôs Languages" />
<link rel="canonical" href="http://localhost:4000/cs336/2025/08/10/cs336-gpt2-regex-for-pretokenization-explaind.html" />
<meta property="og:url" content="http://localhost:4000/cs336/2025/08/10/cs336-gpt2-regex-for-pretokenization-explaind.html" />
<meta property="og:site_name" content="üçí Han‚Äôs Generative AI Quest" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-10T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [4]" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-08-10T00:00:00-07:00","datePublished":"2025-08-10T00:00:00-07:00","description":"Demystifying GPT-2‚Äôs Pre-Tokenization: How One Regex Pattern Handles the World‚Äôs Languages","headline":"Study Notes: Stanford CS336 Language Modeling from Scratch [4]","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/cs336/2025/08/10/cs336-gpt2-regex-for-pretokenization-explaind.html"},"url":"http://localhost:4000/cs336/2025/08/10/cs336-gpt2-regex-for-pretokenization-explaind.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="üçí Han&apos;s Generative AI Quest" />

<!-- MathJax Configuration -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">üçí Han&#39;s Generative AI Quest</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Study Notes: Stanford CS336 Language Modeling from Scratch [4]</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-08-10T00:00:00-07:00" itemprop="datePublished">
        Aug 10, 2025
      </time>‚Ä¢ 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Han Yu</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="demystifying-gpt-2s-pre-tokenization-how-one-regex-pattern-handles-the-worlds-languages">Demystifying GPT-2‚Äôs Pre-Tokenization: How One Regex Pattern Handles the World‚Äôs Languages</h2>

<p>While working on <strong>Assignment 1</strong> of <em>Stanford‚Äôs CS336: Language Modeling from Scratch</em>, I came across a deceptively simple ‚Äî yet remarkably powerful ‚Äî regex pattern used in the pre-tokenization stage of the BPE algorithm.</p>

<p>I thought it would be worthwhile to share my notes and walk through how this single pattern can handle text from <strong>multiple languages, scripts, and symbol sets</strong> with precision.</p>

<p>You can find my full BPE assignment implementation here:</p>
<ul>
  <li><strong>BPE training algorithm:</strong> <a href="https://github.com/bearbearyu1223/assignment1-basics/blob/main/cs336_basics/bpe.py">bpe.py</a></li>
  <li><strong>Tokenizer class:</strong> <a href="https://github.com/bearbearyu1223/assignment1-basics/blob/main/cs336_basics/tokenizer.py">tokenizer.py</a></li>
</ul>

<hr />

<h3 id="-how-to-run-the-bpe-training-process">üîß How to Run the BPE Training Process</h3>

<ol>
  <li><strong>Clone the repository</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/bearbearyu1223/assignment1-basics.git
<span class="nb">cd </span>assignment1-basics
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Set up the local development environment</strong><br />
Follow the instructions in the <a href="https://github.com/bearbearyu1223/assignment1-basics/blob/main/developer_guide.md">developer_guide.md</a>.</p>
  </li>
  <li><strong>Run BPE training</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv run cs336_basics/train_bpe_example.py
</code></pre></div>    </div>
    <p>This will train a BPE tokenizer using the <code class="language-plaintext highlighter-rouge">TinyStoriesV2-GPT4-train.txt</code> dataset, with 10,000 vocabulary size and with special token <code class="language-plaintext highlighter-rouge">"&lt;|endoftext|&gt;"</code>.</p>
  </li>
</ol>

<hr />

<h3 id="-how-to-test-the-tokenizer">üß™ How to Test the Tokenizer</h3>

<p>Run:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv run pytest tests/test_train_bpe.py
</code></pre></div></div>

<p>This will validate the tokenizer‚Äôs functionality and ensure the pre-tokenization regex behaves as expected.</p>

<h3 id="-the-gpt-2-split-pattern">üìú The GPT-2 Split Pattern</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">regex</span>

<span class="n">GPT2_SPLIT_PATTERN</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"""'(?:[sdmt]|ll|ve|re)| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+"""</span>
</code></pre></div></div>

<p>This single (but mighty) regex is responsible for splitting text into meaningful segments ‚Äî <strong>words, numbers, punctuation, symbols, whitespace</strong> ‚Äî in a way that is consistent across languages and scripts.</p>

<hr />

<h3 id="-pattern-breakdown">üîç Pattern Breakdown</h3>

<h4 id="1-contractions">1. Contractions</h4>
<pre><code class="language-regex">'(?:[sdmt]|ll|ve|re)
</code></pre>
<p>Matches <strong>common English contractions</strong> starting with an apostrophe:<br />
<code class="language-plaintext highlighter-rouge">'s, 'd, 'm, 't, 'll, 've, 're</code></p>

<p><strong>Examples:</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">"don't"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["don", "'t"]</code></li>
  <li><code class="language-plaintext highlighter-rouge">"we're"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["we", "'re"]</code></li>
</ul>

<hr />

<h4 id="2-letters-any-language">2. Letters (Any Language)</h4>
<pre><code class="language-regex"> ?\p{L}+
</code></pre>
<p>Matches <strong>letters</strong> from <strong>any Unicode language</strong> (with optional leading space).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">\p{L}</code> = Unicode ‚ÄúLetter‚Äù category</li>
  <li>Covers: English, Chinese, Arabic, accented characters, and more.</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">"hello world"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["hello", " world"]</code></li>
  <li><code class="language-plaintext highlighter-rouge">"caf√© Âåó‰∫¨"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["caf√©", " Âåó‰∫¨"]</code></li>
</ul>

<hr />

<h4 id="3-numbers-any-script">3. Numbers (Any Script)</h4>
<pre><code class="language-regex"> ?\p{N}+
</code></pre>
<p>Matches <strong>numbers</strong> from any writing system (with optional leading space).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">\p{N}</code> = Unicode ‚ÄúNumber‚Äù category</li>
  <li>Covers: Arabic numerals (<code class="language-plaintext highlighter-rouge">0‚Äì9</code>), Roman numerals (<code class="language-plaintext highlighter-rouge">‚Ö†, ‚Ö°, ‚Ö¢</code>), Arabic-Indic (<code class="language-plaintext highlighter-rouge">Ÿ†Ÿ°Ÿ¢</code>), etc.</li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">"I have 5 items"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["I", " have", " 5", " items"]</code></li>
  <li><code class="language-plaintext highlighter-rouge">"‚Ö¢ winners"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["‚Ö¢", " winners"]</code></li>
</ul>

<hr />

<h4 id="4-punctuation--symbols">4. Punctuation / Symbols</h4>
<pre><code class="language-regex"> ?[^\s\p{L}\p{N}]+
</code></pre>
<p>Matches <strong>punctuation or symbols</strong> (with optional leading space).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">[^\s\p{L}\p{N}]</code> = NOT whitespace, NOT letters, NOT numbers</li>
  <li>Captures: <code class="language-plaintext highlighter-rouge">!@#$%^&amp;*()_+-=[]{}|;:'",./&lt;&gt;?</code></li>
</ul>

<p><strong>Examples:</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">"Wow!!!"</code> ‚Üí <code class="language-plaintext highlighter-rouge">["Wow", "!!!"]</code></li>
  <li><code class="language-plaintext highlighter-rouge">" $100"</code> ‚Üí <code class="language-plaintext highlighter-rouge">[" $", "100"]</code></li>
</ul>

<hr />

<h4 id="5-trailing-whitespace">5. Trailing Whitespace</h4>
<pre><code class="language-regex">\s+(?!\S)
</code></pre>
<p>Matches <strong>whitespace at the end</strong> of text or before more whitespace.<br />
This ensures trailing spaces are preserved as tokens.</p>

<hr />

<h4 id="6-general-whitespace">6. General Whitespace</h4>
<pre><code class="language-regex">\s+
</code></pre>
<p>Matches <strong>any remaining whitespace</strong>.</p>

<hr />

<h3 id="-testing-the-pattern">üõ† Testing the Pattern</h3>

<p>Here‚Äôs a helper function to test how this regex splits different inputs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_regex</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s">""</span><span class="p">):</span>
    <span class="s">"""Test the regex pattern and display results clearly"""</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="si">{</span><span class="s">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"TEST: </span><span class="si">{</span><span class="n">description</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"INPUT: '</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="s">'='</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="n">matches</span> <span class="o">=</span> <span class="n">regex</span><span class="p">.</span><span class="n">findall</span><span class="p">(</span><span class="n">GPT2_SPLIT_PATTERN</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"TOKENS (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span><span class="si">}</span><span class="s">):"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">matches</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="mi">2</span><span class="n">d</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="nb">repr</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> 

    <span class="n">reconstructed</span> <span class="o">=</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">RECONSTRUCTION CHECK: </span><span class="si">{</span><span class="s">'‚úì PASS'</span> <span class="k">if</span> <span class="n">reconstructed</span> <span class="o">==</span> <span class="n">text</span> <span class="k">else</span> <span class="s">'‚úó FAIL'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">matches</span>
</code></pre></div></div>

<hr />

<h3 id="-real-world-test-cases">üß™ Real-World Test Cases</h3>

<p>Below are <strong>diverse examples</strong> ‚Äî from contractions to Unicode scripts, punctuation to code.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_cases</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s">"I can't believe it's working!"</span><span class="p">,</span> <span class="s">"Basic contractions"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"You're right, they'll see we've done it."</span><span class="p">,</span> <span class="s">"Multiple contractions"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"Hello ‰∏ñÁïå! Caf√© fran√ßais üåç"</span><span class="p">,</span> <span class="s">"Unicode letters and emoji"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"I have 5 cats, Ÿß dogs, and ‚Ö¢ birds."</span><span class="p">,</span> <span class="s">"Various number systems"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"Wait... What?!? $100.50 (seriously)!!!"</span><span class="p">,</span> <span class="s">"Complex punctuation"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"  Multiple   spaces   everywhere  "</span><span class="p">,</span> <span class="s">"Multiple spaces"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"She's got $1,000.50 in caf√© ‚Ññ Ÿß... Amazing!!! üöÄ"</span><span class="p">,</span> <span class="s">"Complex mixed text"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"'s'd'm't'll've're"</span><span class="p">,</span> <span class="s">"Contraction edge cases"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"!@#$%^&amp;*()_+-=[]{}|;:"</span><span class="p">,.</span><span class="o">/&lt;&gt;</span><span class="err">?</span><span class="s">", "</span><span class="n">Pure</span> <span class="n">punctuation</span><span class="s">"),
    ("</span>   \<span class="n">t</span>\<span class="n">n</span>  <span class="s">", "</span><span class="n">Pure</span> <span class="n">whitespace</span><span class="s">"),
    ("", "</span><span class="n">Empty</span> <span class="n">string</span><span class="s">"),
    ("</span><span class="n">a</span> <span class="mi">1</span> <span class="err">!</span> <span class="s">'", "Single characters"),
    ("ÊàëÊúâ3Âè™Áå´ÔºåÂæàÂèØÁà±ÔºÅ", "Chinese with numbers"),
    ("ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ Ÿ°Ÿ¢Ÿ£", "Arabic text with numbers"),
    ("def hello_world(): return '</span><span class="n">Hello</span><span class="p">,</span> <span class="n">World</span><span class="err">!</span><span class="s">'", "Code-like text"),
    ("Visit https://example.com or email test@domain.co.uk", "URLs and emails"),
]

for text, description in test_cases:
    test_regex(text, description)
</span></code></pre></div></div>

<p>Running these cases produces token lists that <strong>perfectly reconstruct the original text</strong>, see the test results below:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ============================================================
    TEST: Basic contractions
    INPUT: 'I can't believe it's working!'
    ============================================================
    TOKENS (8):
       1: 'I'
       2: ' can'
       3: "'t"
       4: ' believe'
       5: ' it'
       6: "'s"
       7: ' working'
       8: '!'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Multiple contractions
    INPUT: 'You're right, they'll see we've done it.'
    ============================================================
    TOKENS (12):
       1: 'You'
       2: "'re"
       3: ' right'
       4: ','
       5: ' they'
       6: "'ll"
       7: ' see'
       8: ' we'
       9: "'ve"
      10: ' done'
      11: ' it'
      12: '.'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Unicode letters and emoji
    INPUT: 'Hello ‰∏ñÁïå! Caf√© fran√ßais üåç'
    ============================================================
    TOKENS (6):
       1: 'Hello'
       2: ' ‰∏ñÁïå'
       3: '!'
       4: ' Caf√©'
       5: ' fran√ßais'
       6: ' üåç'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Various number systems
    INPUT: 'I have 5 cats, Ÿß dogs, and ‚Ö¢ birds.'
    ============================================================
    TOKENS (12):
       1: 'I'
       2: ' have'
       3: ' 5'
       4: ' cats'
       5: ','
       6: ' Ÿß'
       7: ' dogs'
       8: ','
       9: ' and'
      10: ' ‚Ö¢'
      11: ' birds'
      12: '.'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Complex punctuation
    INPUT: 'Wait... What?!? $100.50 (seriously)!!!'
    ============================================================
    TOKENS (11):
       1: 'Wait'
       2: '...'
       3: ' What'
       4: '?!?'
       5: ' $'
       6: '100'
       7: '.'
       8: '50'
       9: ' ('
      10: 'seriously'
      11: ')!!!'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Multiple spaces
    INPUT: '  Multiple   spaces   everywhere  '
    ============================================================
    TOKENS (7):
       1: ' '
       2: ' Multiple'
       3: '  '
       4: ' spaces'
       5: '  '
       6: ' everywhere'
       7: '  '
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Complex mixed text
    INPUT: 'She's got $1,000.50 in caf√© ‚Ññ Ÿß... Amazing!!! üöÄ'
    ============================================================
    TOKENS (17):
       1: 'She'
       2: "'s"
       3: ' got'
       4: ' $'
       5: '1'
       6: ','
       7: '000'
       8: '.'
       9: '50'
      10: ' in'
      11: ' caf√©'
      12: ' ‚Ññ'
      13: ' Ÿß'
      14: '...'
      15: ' Amazing'
      16: '!!!'
      17: ' üöÄ'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Contraction edge cases
    INPUT: ''s'd'm't'll've're'
    ============================================================
    TOKENS (7):
       1: "'s"
       2: "'d"
       3: "'m"
       4: "'t"
       5: "'ll"
       6: "'ve"
       7: "'re"
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Pure punctuation
    INPUT: '!@#$%^&amp;*()_+-=[]{}|;:",./&lt;&gt;?'
    ============================================================
    TOKENS (1):
       1: '!@#$%^&amp;*()_+-=[]{}|;:",./&lt;&gt;?'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Pure whitespace
    INPUT: '   	
      '
    ============================================================
    TOKENS (1):
       1: '   \t\n  '
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Empty string
    INPUT: ''
    ============================================================
    TOKENS (0):
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Single characters
    INPUT: 'a 1 ! ''
    ============================================================
    TOKENS (4):
       1: 'a'
       2: ' 1'
       3: ' !'
       4: " '"
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Chinese with numbers
    INPUT: 'ÊàëÊúâ3Âè™Áå´ÔºåÂæàÂèØÁà±ÔºÅ'
    ============================================================
    TOKENS (6):
       1: 'ÊàëÊúâ'
       2: '3'
       3: 'Âè™Áå´'
       4: 'Ôºå'
       5: 'ÂæàÂèØÁà±'
       6: 'ÔºÅ'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Arabic text with numbers
    INPUT: 'ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ Ÿ°Ÿ¢Ÿ£'
    ============================================================
    TOKENS (3):
       1: 'ŸÖÿ±ÿ≠ÿ®ÿß'
       2: ' ÿ®ÿßŸÑÿπÿßŸÑŸÖ'
       3: ' Ÿ°Ÿ¢Ÿ£'
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: Code-like text
    INPUT: 'def hello_world(): return 'Hello, World!''
    ============================================================
    TOKENS (11):
       1: 'def'
       2: ' hello'
       3: '_'
       4: 'world'
       5: '():'
       6: ' return'
       7: " '"
       8: 'Hello'
       9: ','
      10: ' World'
      11: "!'"
    
    RECONSTRUCTION CHECK: ‚úì PASS
    
    ============================================================
    TEST: URLs and emails
    INPUT: 'Visit https://example.com or email test@domain.co.uk'
    ============================================================
    TOKENS (15):
       1: 'Visit'
       2: ' https'
       3: '://'
       4: 'example'
       5: '.'
       6: 'com'
       7: ' or'
       8: ' email'
       9: ' test'
      10: '@'
      11: 'domain'
      12: '.'
      13: 'co'
      14: '.'
      15: 'uk'
    
    RECONSTRUCTION CHECK: ‚úì PASS
</code></pre></div></div>

<hr />

<h3 id="-why-this-matters">üí° Why This Matters</h3>

<p>BPE pre-tokenization <strong>sets the stage</strong> for the tokenizer‚Äôs merge rules to apply. A well-designed split pattern ensures:</p>

<ul>
  <li><strong>Language independence</strong> ‚Äî Works with English, Arabic, Chinese, emoji, etc.</li>
  <li><strong>Symbol awareness</strong> ‚Äî Keeps punctuation and symbols intact.</li>
  <li><strong>Whitespace fidelity</strong> ‚Äî Preserves exact spacing for reversible tokenization.</li>
  <li><strong>Downstream accuracy</strong> ‚Äî Reduces surprises during model training or inference.</li>
</ul>

<hr />

<h3 id="-takeaways">üöÄ Takeaways</h3>

<ul>
  <li>This regex is a <strong>core building block</strong> of GPT-2‚Äôs tokenization process.</li>
  <li>It‚Äôs <strong>language-agnostic</strong>, <strong>Unicode-friendly</strong>, and <strong>precise</strong> in splitting.</li>
  <li>Understanding it helps when <strong>building custom tokenizers</strong> or adapting GPT-2 BPE to new domains.</li>
</ul>

<p>If you‚Äôre working with <strong>LLMs, tokenization, or multilingual NLP</strong>, knowing the details behind this pattern will help you <strong>debug</strong>, <strong>customize</strong>, and <strong>optimize</strong> your preprocessing pipeline.</p>

  </div><a class="u-url" href="/cs336/2025/08/10/cs336-gpt2-regex-for-pretokenization-explaind.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>I chronicle my captivating journey through Generative AI, sharing insights,  breakthroughs, and learnings from my enthralling side projects in the field. 
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
