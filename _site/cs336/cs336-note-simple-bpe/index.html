<!DOCTYPE html>
<html lang="en"><head>
  <link rel="shortcut icon" type="image/png" href="/assets/favicon.png">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Study Notes: Stanford CS336 Language Modeling from Scratch [2] | ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [2]" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development." />
<meta property="og:description" content="A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development." />
<link rel="canonical" href="http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-simple-bpe/" />
<meta property="og:url" content="http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-simple-bpe/" />
<meta property="og:site_name" content="ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-22T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Study Notes: Stanford CS336 Language Modeling from Scratch [2]" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-22T00:00:00-07:00","datePublished":"2025-07-22T00:00:00-07:00","description":"A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development.","headline":"Study Notes: Stanford CS336 Language Modeling from Scratch [2]","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-simple-bpe/"},"url":"http://localhost:4000/chinese-online-content-for-llm/cs336/cs336-note-simple-bpe/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/chinese-online-content-for-llm/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/chinese-online-content-for-llm/feed.xml" title="ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±" /><link rel="stylesheet" href="/chinese-online-content-for-llm/assets/css/dark-mode.css">
<script src="/chinese-online-content-for-llm/assets/js/theme-toggle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/chinese-online-content-for-llm/">ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/chinese-online-content-for-llm/cs336/">ğŸ“š Stanford CS336</a><a class="page-link" href="/chinese-online-content-for-llm/career/">ğŸŒ± Career &amp; Growth</a><a class="page-link" href="/chinese-online-content-for-llm/ai-insights/">ğŸ§¬ AI Insights</a><a class="page-link" href="/chinese-online-content-for-llm/about/">å…³äºæœ¬ç«™</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Study Notes: Stanford CS336 Language Modeling from Scratch [2]</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-07-22T00:00:00-07:00" itemprop="datePublished">
        Jul 22, 2025
      </time>â€¢ 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <style>
  .xiaohongshu-link {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    color: #ff2442; /* å°çº¢ä¹¦ä¸»è‰² */
    text-decoration: none;
    font-weight: bold;
    font-size: 14px;
  }
  .xiaohongshu-link:hover {
    text-decoration: underline;
  }
  .xiaohongshu-logo {
    width: 18px;
    height: 18px;
    border-radius: 4px;
  }
</style>

<div style="padding:12px;border:1px solid #eee;border-radius:8px;display:inline-block;margin-bottom:20px;">
  <strong>å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</strong><br />
  <p style="margin:4px 0;">
    å°çº¢ä¹¦å·ï¼š
    <a class="xiaohongshu-link" href="https://www.xiaohongshu.com/user/profile/5b2c5758e8ac2b08bf20e38d" target="_blank">
      <img class="xiaohongshu-logo" src="https://static.cdnlogo.com/logos/r/77/rednote-xiaohongshu.svg" alt="å°çº¢ä¹¦ logo" />
      119826921
    </a>
  </p>
  IPå±åœ°ï¼šç¾å›½
</div>

<h1 id="byte-pair-encoding-bpe-tokenizer-in-a-nutshell">Byte Pair Encoding (BPE) Tokenizer in a Nutshell</h1>

<h1 id="å­—èŠ‚å¯¹ç¼–ç bpeåˆ†è¯å™¨ç®€è¿°">å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰åˆ†è¯å™¨ç®€è¿°</h1>

<hr />

<h2 id="key-terms">Key Terms</h2>

<h2 id="å…³é”®æœ¯è¯­">å…³é”®æœ¯è¯­</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Concept</th>
      <th style="text-align: left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Unicode</td>
      <td style="text-align: left">System that assigns every character a unique codepoint (e.g., â€˜Aâ€™ â†’ 65)</td>
    </tr>
    <tr>
      <td style="text-align: left">UTF-8</td>
      <td style="text-align: left">A way to encode those codepoints into 1-4 bytes</td>
    </tr>
    <tr>
      <td style="text-align: left">Byte</td>
      <td style="text-align: left">8 bits; one byte can hold values from 0 to 255</td>
    </tr>
    <tr>
      <td style="text-align: left">Tokenization</td>
      <td style="text-align: left">Breaking text corpus input into manageable pieces (tokens) for a model</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: left">æ¦‚å¿µ</th>
      <th style="text-align: left">æè¿°</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Unicode</td>
      <td style="text-align: left">ä¸ºæ¯ä¸ªå­—ç¬¦åˆ†é…å”¯ä¸€ä»£ç ç‚¹çš„ç³»ç»Ÿï¼ˆä¾‹å¦‚ï¼Œâ€™Aâ€™ â†’ 65ï¼‰</td>
    </tr>
    <tr>
      <td style="text-align: left">UTF-8</td>
      <td style="text-align: left">å°†è¿™äº›ä»£ç ç‚¹ç¼–ç ä¸º1-4å­—èŠ‚çš„æ–¹æ³•</td>
    </tr>
    <tr>
      <td style="text-align: left">å­—èŠ‚</td>
      <td style="text-align: left">8ä½ï¼›ä¸€ä¸ªå­—èŠ‚å¯ä»¥ä¿å­˜0åˆ°255çš„å€¼</td>
    </tr>
    <tr>
      <td style="text-align: left">åˆ†è¯</td>
      <td style="text-align: left">å°†æ–‡æœ¬è¯­æ–™åº“è¾“å…¥åˆ†è§£ä¸ºæ¨¡å‹å¯ç®¡ç†çš„ç‰‡æ®µï¼ˆæ ‡è®°ï¼‰</td>
    </tr>
  </tbody>
</table>

<hr />

<p>Let us take the following string as a simple example to illustrate the concept.</p>

<p>è®©æˆ‘ä»¬ä»¥ä¸‹é¢çš„å­—ç¬¦ä¸²ä½œä¸ºä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜è¿™ä¸ªæ¦‚å¿µã€‚</p>

<hr />

<h2 id="example-encoding-a">Example: Encoding â€˜AğŸ˜Šâ€™</h2>

<h2 id="ç¤ºä¾‹ç¼–ç a">ç¤ºä¾‹ï¼šç¼–ç â€™AğŸ˜Šâ€™</h2>

<hr />

<h3 id="step-1-get-the-unicode-codepoints">Step 1: Get the Unicode Codepoints</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="s">'AğŸ˜Š'</span>
<span class="n">codepoints</span> <span class="o">=</span> <span class="p">[</span><span class="nb">ord</span><span class="p">(</span><span class="s">'A'</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s">'ğŸ˜Š'</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="n">codepoints</span><span class="p">)</span>  <span class="c1"># [65, 128522]
</span></code></pre></div></div>

<p>Output:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[65, 128522]
</code></pre></div></div>

<h3 id="æ­¥éª¤1è·å–unicodeä»£ç ">æ­¥éª¤1ï¼šè·å–Unicodeä»£ç </h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="s">'AğŸ˜Š'</span>
<span class="n">codepoints</span> <span class="o">=</span> <span class="p">[</span><span class="nb">ord</span><span class="p">(</span><span class="s">'A'</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s">'ğŸ˜Š'</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="n">codepoints</span><span class="p">)</span>  <span class="c1"># [65, 128522]
</span></code></pre></div></div>

<p>è¾“å‡ºï¼š</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[65, 128522]
</code></pre></div></div>

<hr />

<h3 id="step-2-utf-8-encoding-turn-codepoints-into-bytes">Step 2: UTF-8 Encoding (Turn Codepoints into Bytes)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">utf8_bytes</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">utf8_bytes</span><span class="p">))</span>  <span class="c1"># (65, 240, 159, 152, 138)
</span></code></pre></div></div>

<p>Output:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(65, 240, 159, 152, 138)
</code></pre></div></div>

<p>Hereâ€™s what happened:</p>
<ul>
  <li>â€˜Aâ€™ is encoded using one byte: 65</li>
  <li>â€˜ğŸ˜Šâ€™ is encoded using four bytes: [240, 159, 152, 138]</li>
  <li>â€˜AğŸ˜Šâ€™ is encoded as the sequence [65, 240, 159, 152, 138]</li>
</ul>

<h3 id="æ­¥éª¤2utf-8ç¼–ç å°†ä»£ç è½¬æ¢ä¸ºå­—èŠ‚">æ­¥éª¤2ï¼šUTF-8ç¼–ç ï¼ˆå°†ä»£ç è½¬æ¢ä¸ºå­—èŠ‚ï¼‰</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">utf8_bytes</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">utf8_bytes</span><span class="p">))</span>  <span class="c1"># (65, 240, 159, 152, 138)
</span></code></pre></div></div>

<p>è¾“å‡ºï¼š</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(65, 240, 159, 152, 138)
</code></pre></div></div>

<p>å‘ç”Ÿäº†ä»€ä¹ˆï¼š</p>
<ul>
  <li>â€˜Aâ€™ ä½¿ç”¨ä¸€ä¸ªå­—èŠ‚ç¼–ç ï¼š65</li>
  <li>â€˜ğŸ˜Šâ€™ ä½¿ç”¨å››ä¸ªå­—èŠ‚ç¼–ç ï¼š[240, 159, 152, 138]</li>
  <li>â€˜AğŸ˜Šâ€™ è¢«ç¼–ç ä¸ºåºåˆ— [65, 240, 159, 152, 138]</li>
</ul>

<hr />

<h2 id="why-using-utf-8-for-encoding-is-helpful">Why Using UTF-8 for Encoding is Helpful</h2>

<p>Instead of dealing with hundreds of thousands of possible codepoints (Unicode has more than 150,000 codepoints) or millions of words/subwords in vocabulary, we can model text using sequences of bytes. Each byte can be represented by an integer from 0 to 255, so we only need a vocabulary of size 256 to model input text. This approach is simple and completeâ€”any character in any language can be represented as bytes, eliminating out-of-vocabulary token concerns.</p>

<h2 id="ä¸ºä»€ä¹ˆä½¿ç”¨utf-8ç¼–ç å¾ˆæœ‰å¸®åŠ©">ä¸ºä»€ä¹ˆä½¿ç”¨UTF-8ç¼–ç å¾ˆæœ‰å¸®åŠ©</h2>

<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å­—èŠ‚åºåˆ—æ¥å»ºæ¨¡æ–‡æœ¬ï¼Œè€Œä¸æ˜¯å¤„ç†æ•°åä¸‡ä¸ªå¯èƒ½çš„ä»£ç ç‚¹ï¼ˆUnicodeæœ‰è¶…è¿‡150,000ä¸ªä»£ç ç‚¹ï¼‰æˆ–è¯æ±‡è¡¨ä¸­çš„æ•°ç™¾ä¸‡ä¸ªå•è¯/å­è¯ã€‚æ¯ä¸ªå­—èŠ‚å¯ä»¥ç”¨0åˆ°255ä¹‹é—´çš„æ•´æ•°è¡¨ç¤ºï¼Œå› æ­¤æˆ‘ä»¬åªéœ€è¦å¤§å°ä¸º256çš„è¯æ±‡è¡¨æ¥å»ºæ¨¡è¾“å…¥æ–‡æœ¬ã€‚è¿™ç§æ–¹æ³•ç®€å•ä¸”å®Œæ•´â€”â€”ä»»ä½•è¯­è¨€ä¸­çš„ä»»ä½•å­—ç¬¦éƒ½å¯ä»¥è¡¨ç¤ºä¸ºå­—èŠ‚ï¼Œæ¶ˆé™¤äº†è¯æ±‡è¡¨å¤–æ ‡è®°çš„é—®é¢˜ã€‚</p>

<hr />

<h2 id="tokenization-spectrum">Tokenization Spectrum</h2>

<h2 id="åˆ†è¯èŒƒå›´">åˆ†è¯èŒƒå›´</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Tokenization Level</th>
      <th style="text-align: left">Example Tokens</th>
      <th style="text-align: left">Pros</th>
      <th style="text-align: left">Cons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Word-level</strong></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">["unbelievable"]</code></td>
      <td style="text-align: left">Human-readable, efficient</td>
      <td style="text-align: left">OOV (out-of-vocabulary) issues</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Subword-level</strong> (BPE)</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">["un", "believ", "able"]</code></td>
      <td style="text-align: left">Handles rare words, compact</td>
      <td style="text-align: left">Requires training</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Byte-level</strong></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[117, 110, 98, 101, ...]</code> (bytes)</td>
      <td style="text-align: left">No OOV, simple</td>
      <td style="text-align: left">Longer sequences, less semantic meaning</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th style="text-align: left">åˆ†è¯çº§åˆ«</th>
      <th style="text-align: left">ç¤ºä¾‹æ ‡è®°</th>
      <th style="text-align: left">ä¼˜ç‚¹</th>
      <th style="text-align: left">ç¼ºç‚¹</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>è¯çº§</strong></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">["unbelievable"]</code></td>
      <td style="text-align: left">äººç±»å¯è¯»ï¼Œé«˜æ•ˆ</td>
      <td style="text-align: left">OOVï¼ˆè¯æ±‡è¡¨å¤–ï¼‰é—®é¢˜</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>å­è¯çº§</strong> (BPE)</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">["un", "believ", "able"]</code></td>
      <td style="text-align: left">å¤„ç†ç½•è§è¯ï¼Œç´§å‡‘</td>
      <td style="text-align: left">éœ€è¦è®­ç»ƒ</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>å­—èŠ‚çº§</strong></td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">[117, 110, 98, 101, ...]</code> (å­—èŠ‚)</td>
      <td style="text-align: left">æ— OOVï¼Œç®€å•</td>
      <td style="text-align: left">åºåˆ—æ›´é•¿ï¼Œè¯­ä¹‰æ„ä¹‰è¾ƒå°‘</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="why-subword-tokenization-is-the-middle-ground">Why Subword Tokenization is the Middle Ground</h2>

<p><strong>Subword tokenization</strong> with <strong>Byte Pair Encoding (BPE)</strong> provides a balance between the other approaches:</p>

<ul>
  <li><strong>Word-level tokenization</strong> struggles with rare or unseen words (e.g., â€œunbelievableâ€ might be unknown even if â€œbelieveâ€ is known)</li>
  <li><strong>Byte-level tokenization</strong> avoids unknown token issues but creates long, inefficient sequences</li>
  <li><strong>Subword tokenization</strong> (BPE):
    <ol>
      <li>Breaks rare words into familiar pieces (subwords)</li>
      <li>Retains compactness for common words</li>
      <li>Is learnable from corpus statistics</li>
    </ol>
  </li>
</ul>

<h2 id="ä¸ºä»€ä¹ˆå­è¯åˆ†è¯æ˜¯ä¸­é—´åœ°å¸¦">ä¸ºä»€ä¹ˆå­è¯åˆ†è¯æ˜¯ä¸­é—´åœ°å¸¦</h2>

<p>ä½¿ç”¨<strong>å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰</strong>çš„<strong>å­è¯åˆ†è¯</strong>åœ¨å…¶ä»–æ–¹æ³•ä¹‹é—´æä¾›äº†å¹³è¡¡ï¼š</p>

<ul>
  <li><strong>è¯çº§åˆ†è¯</strong>åœ¨å¤„ç†ç½•è§æˆ–æœªè§è¿‡çš„è¯æ—¶é‡åˆ°å›°éš¾ï¼ˆä¾‹å¦‚ï¼Œå³ä½¿â€believeâ€æ˜¯å·²çŸ¥çš„ï¼Œâ€unbelievableâ€å¯èƒ½æ˜¯æœªçŸ¥çš„ï¼‰</li>
  <li><strong>å­—èŠ‚çº§åˆ†è¯</strong>é¿å…äº†æœªçŸ¥æ ‡è®°é—®é¢˜ï¼Œä½†åˆ›å»ºäº†å†—é•¿ã€ä½æ•ˆçš„åºåˆ—</li>
  <li><strong>å­è¯åˆ†è¯</strong>ï¼ˆBPEï¼‰ï¼š
    <ol>
      <li>å°†ç½•è§è¯åˆ†è§£ä¸ºç†Ÿæ‚‰çš„ç‰‡æ®µï¼ˆå­è¯ï¼‰</li>
      <li>ä¿æŒå¸¸è§è¯çš„ç´§å‡‘æ€§</li>
      <li>å¯ä»¥ä»è¯­æ–™åº“ç»Ÿè®¡ä¸­å­¦ä¹ </li>
    </ol>
  </li>
</ul>

<hr />

<h2 id="byte-pair-encoding-bpe-algorithm-overview">Byte Pair Encoding (BPE) Algorithm Overview</h2>

<p>BPE starts from characters and iteratively <strong>merges the most frequent adjacent pairs</strong> into longer tokens.</p>

<h2 id="å­—èŠ‚å¯¹ç¼–ç bpeç®—æ³•æ¦‚è¿°">å­—èŠ‚å¯¹ç¼–ç ï¼ˆBPEï¼‰ç®—æ³•æ¦‚è¿°</h2>

<p>BPEä»å­—ç¬¦å¼€å§‹ï¼Œè¿­ä»£åœ°<strong>å°†æœ€é¢‘ç¹çš„ç›¸é‚»å¯¹åˆå¹¶</strong>ä¸ºæ›´é•¿çš„æ ‡è®°ã€‚</p>

<hr />

<h3 id="example-training-corpus">Example Training Corpus</h3>

<p>Consider this toy training corpus:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low"     (5 times)
"lowest"  (2 times)
"newest"  (6 times)
"wider"   (3 times)
</code></pre></div></div>

<p>We want to learn a compact subword vocabulary that reuses frequent patterns like â€œlowâ€ and â€œestâ€.</p>

<h3 id="ç¤ºä¾‹è®­ç»ƒè¯­æ–™åº“">ç¤ºä¾‹è®­ç»ƒè¯­æ–™åº“</h3>

<p>è€ƒè™‘è¿™ä¸ªç©å…·è®­ç»ƒè¯­æ–™åº“ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low"     (5æ¬¡)
"lowest"  (2æ¬¡)
"newest"  (6æ¬¡)
"wider"   (3æ¬¡)
</code></pre></div></div>

<p>æˆ‘ä»¬æƒ³è¦å­¦ä¹ ä¸€ä¸ªç´§å‡‘çš„å­è¯è¯æ±‡è¡¨ï¼Œé‡ç”¨åƒâ€lowâ€å’Œâ€estâ€è¿™æ ·çš„é¢‘ç¹æ¨¡å¼ã€‚</p>

<hr />

<h3 id="step-by-step-bpe-process">Step-by-Step BPE Process</h3>

<h3 id="é€æ­¥bpeè¿‡ç¨‹">é€æ­¥BPEè¿‡ç¨‹</h3>

<hr />

<h4 id="step-0-preprocess-as-characters">Step 0: Preprocess as Characters</h4>

<p>Each word is broken into characters with an end-of-word marker <code class="language-plaintext highlighter-rouge">&lt;/w&gt;</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"        (5)
"l o w e s t &lt;/w&gt;"  (2)
"n e w e s t &lt;/w&gt;"  (6)
"w i d e r &lt;/w&gt;"    (3)
</code></pre></div></div>

<h4 id="æ­¥éª¤0é¢„å¤„ç†ä¸ºå­—ç¬¦">æ­¥éª¤0ï¼šé¢„å¤„ç†ä¸ºå­—ç¬¦</h4>

<p>æ¯ä¸ªå•è¯è¢«åˆ†è§£ä¸ºå­—ç¬¦ï¼Œå¸¦æœ‰è¯å°¾æ ‡è®°<code class="language-plaintext highlighter-rouge">&lt;/w&gt;</code>ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"        (5)
"l o w e s t &lt;/w&gt;"  (2)
"n e w e s t &lt;/w&gt;"  (6)
"w i d e r &lt;/w&gt;"    (3)
</code></pre></div></div>

<hr />

<h4 id="step-1-count-adjacent-pairs">Step 1: Count Adjacent Pairs</h4>

<p>Compute most frequent adjacent pairs across all words:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('e', 's') appears 8 times
('s', 't') appears 8 times
('l', 'o') appears 7 times
('o', 'w') appears 7 times
</code></pre></div></div>

<h4 id="æ­¥éª¤1è®¡æ•°ç›¸é‚»å¯¹">æ­¥éª¤1ï¼šè®¡æ•°ç›¸é‚»å¯¹</h4>

<p>è®¡ç®—æ‰€æœ‰å•è¯ä¸­æœ€é¢‘ç¹çš„ç›¸é‚»å¯¹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>('e', 's') å‡ºç°8æ¬¡
('s', 't') å‡ºç°8æ¬¡
('l', 'o') å‡ºç°7æ¬¡
('o', 'w') å‡ºç°7æ¬¡
</code></pre></div></div>

<hr />

<h4 id="step-2-merge-e--s--es">Step 2: Merge â€˜eâ€™ + â€˜sâ€™ â†’ â€˜esâ€™</h4>

<p>Update vocabulary:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"          (5)
"l o w es t &lt;/w&gt;"     (2)
"n e w es t &lt;/w&gt;"     (6)
"w i d e r &lt;/w&gt;"      (3)
</code></pre></div></div>

<h4 id="æ­¥éª¤2åˆå¹¶-e--s--es">æ­¥éª¤2ï¼šåˆå¹¶ â€˜eâ€™ + â€˜sâ€™ â†’ â€˜esâ€™</h4>

<p>æ›´æ–°è¯æ±‡è¡¨ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"          (5)
"l o w es t &lt;/w&gt;"     (2)
"n e w es t &lt;/w&gt;"     (6)
"w i d e r &lt;/w&gt;"      (3)
</code></pre></div></div>

<hr />

<h4 id="step-3-merge-es--t--est">Step 3: Merge â€˜esâ€™ + â€˜tâ€™ â†’ â€˜estâ€™</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"         (5)
"l o w est &lt;/w&gt;"     (2)
"n e w est &lt;/w&gt;"     (6)
"w i d e r &lt;/w&gt;"     (3)
</code></pre></div></div>

<h4 id="æ­¥éª¤3åˆå¹¶-es--t--est">æ­¥éª¤3ï¼šåˆå¹¶ â€˜esâ€™ + â€˜tâ€™ â†’ â€˜estâ€™</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"l o w &lt;/w&gt;"         (5)
"l o w est &lt;/w&gt;"     (2)
"n e w est &lt;/w&gt;"     (6)
"w i d e r &lt;/w&gt;"     (3)
</code></pre></div></div>

<hr />

<h4 id="step-4-merge-l--o--lo-then-lo--w--low">Step 4: Merge â€˜lâ€™ + â€˜oâ€™ â†’ â€˜loâ€™, then â€˜loâ€™ + â€˜wâ€™ â†’ â€˜lowâ€™</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low &lt;/w&gt;"          (5)
"low est &lt;/w&gt;"      (2)
"n e w est &lt;/w&gt;"    (6)
"w i d e r &lt;/w&gt;"    (3)
</code></pre></div></div>

<h4 id="æ­¥éª¤4åˆå¹¶-l--o--loç„¶å-lo--w--low">æ­¥éª¤4ï¼šåˆå¹¶ â€˜lâ€™ + â€˜oâ€™ â†’ â€˜loâ€™ï¼Œç„¶å â€˜loâ€™ + â€˜wâ€™ â†’ â€˜lowâ€™</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low &lt;/w&gt;"          (5)
"low est &lt;/w&gt;"      (2)
"n e w est &lt;/w&gt;"    (6)
"w i d e r &lt;/w&gt;"    (3)
</code></pre></div></div>

<hr />

<h4 id="continue-merging">Continue mergingâ€¦</h4>

<p>Eventually we learn useful building blocks like â€˜lowâ€™, â€˜estâ€™, and â€˜newâ€™. After training, â€œnewestâ€ would tokenize to <code class="language-plaintext highlighter-rouge">['new', 'est', '&lt;/w&gt;']</code>.</p>

<h4 id="ç»§ç»­åˆå¹¶">ç»§ç»­åˆå¹¶â€¦</h4>

<p>æœ€ç»ˆæˆ‘ä»¬å­¦ä¹ åˆ°æœ‰ç”¨çš„æ„å»ºå—ï¼Œå¦‚â€™lowâ€™ã€â€™estâ€™å’Œâ€™newâ€™ã€‚è®­ç»ƒåï¼Œâ€newestâ€å°†è¢«åˆ†è¯ä¸º<code class="language-plaintext highlighter-rouge">['new', 'est', '&lt;/w&gt;']</code>ã€‚</p>

<hr />

<h2 id="bpe-implementation">BPE Implementation</h2>

<p>Below is a complete implementation demonstrating the BPE algorithm on the corpus:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low low low low low lower lower widest widest widest newest newest newest newest newest newest"
</code></pre></div></div>

<h2 id="bpeå®ç°">BPEå®ç°</h2>

<p>ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„å®ç°ï¼Œæ¼”ç¤ºäº†åœ¨è¯­æ–™åº“ä¸Šçš„BPEç®—æ³•ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"low low low low low lower lower widest widest widest newest newest newest newest newest newest"
</code></pre></div></div>

<hr />

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Initialization</strong>: Creates vocabulary with <code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code> special token and all 256 byte values</li>
  <li><strong>Pre-tokenization</strong>: Splits text on whitespace and converts words to byte tuples</li>
  <li><strong>Pair Frequency Counting</strong>: Counts all adjacent byte pairs across the corpus</li>
  <li><strong>Merging</strong>: Merges the most frequent pair (lexicographically largest in case of ties)</li>
  <li><strong>Tokenization</strong>: Uses learned merges to tokenize new words</li>
</ol>

<h3 id="å…³é”®ç»„ä»¶">å…³é”®ç»„ä»¶</h3>

<ol>
  <li><strong>åˆå§‹åŒ–</strong>ï¼šåˆ›å»ºåŒ…å«<code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>ç‰¹æ®Šæ ‡è®°å’Œæ‰€æœ‰256ä¸ªå­—èŠ‚å€¼çš„è¯æ±‡è¡¨</li>
  <li><strong>é¢„åˆ†è¯</strong>ï¼šåœ¨ç©ºæ ¼å¤„åˆ†å‰²æ–‡æœ¬å¹¶å°†å•è¯è½¬æ¢ä¸ºå­—èŠ‚å…ƒç»„</li>
  <li><strong>å¯¹é¢‘ç‡è®¡æ•°</strong>ï¼šè®¡ç®—è¯­æ–™åº“ä¸­æ‰€æœ‰ç›¸é‚»å­—èŠ‚å¯¹</li>
  <li><strong>åˆå¹¶</strong>ï¼šåˆå¹¶æœ€é¢‘ç¹çš„å¯¹ï¼ˆåœ¨å¹³å±€çš„æƒ…å†µä¸‹é€‰æ‹©å­—å…¸åºæœ€å¤§çš„ï¼‰</li>
  <li><strong>åˆ†è¯</strong>ï¼šä½¿ç”¨å­¦ä¹ åˆ°çš„åˆå¹¶æ¥åˆ†è¯æ–°å•è¯</li>
</ol>

<hr />

<h3 id="how-it-works">How It Works</h3>

<ol>
  <li><strong>Pre-tokenization</strong>: Converts <code class="language-plaintext highlighter-rouge">"low low low..."</code> into <code class="language-plaintext highlighter-rouge">{(l,o,w): 5, (l,o,w,e,r): 2, ...}</code></li>
  <li><strong>Merge Selection</strong>: Finds most frequent pairs like <code class="language-plaintext highlighter-rouge">('s','t')</code> and <code class="language-plaintext highlighter-rouge">('e','s')</code>, chooses lexicographically larger <code class="language-plaintext highlighter-rouge">('s','t')</code></li>
  <li><strong>Iterative Merging</strong>: Continues merging until desired number of merges is reached</li>
  <li><strong>Tokenization</strong>: Applies learned merges in order to tokenize new words</li>
</ol>

<h3 id="å·¥ä½œåŸç†">å·¥ä½œåŸç†</h3>

<ol>
  <li><strong>é¢„åˆ†è¯</strong>ï¼šå°†<code class="language-plaintext highlighter-rouge">"low low low..."</code>è½¬æ¢ä¸º<code class="language-plaintext highlighter-rouge">{(l,o,w): 5, (l,o,w,e,r): 2, ...}</code></li>
  <li><strong>åˆå¹¶é€‰æ‹©</strong>ï¼šæ‰¾åˆ°æœ€é¢‘ç¹çš„å¯¹ï¼Œå¦‚<code class="language-plaintext highlighter-rouge">('s','t')</code>å’Œ<code class="language-plaintext highlighter-rouge">('e','s')</code>ï¼Œé€‰æ‹©å­—å…¸åºè¾ƒå¤§çš„<code class="language-plaintext highlighter-rouge">('s','t')</code></li>
  <li><strong>è¿­ä»£åˆå¹¶</strong>ï¼šç»§ç»­åˆå¹¶ï¼Œç›´åˆ°è¾¾åˆ°æ‰€éœ€çš„åˆå¹¶æ¬¡æ•°</li>
  <li><strong>åˆ†è¯</strong>ï¼šæŒ‰é¡ºåºåº”ç”¨å­¦ä¹ åˆ°çš„åˆå¹¶æ¥åˆ†è¯æ–°å•è¯</li>
</ol>

<hr />

<h3 id="expected-output">Expected Output</h3>

<p>With 6 merges, the algorithm produces:</p>
<ul>
  <li><strong>Merges</strong>: <code class="language-plaintext highlighter-rouge">['s t', 'e st', 'o w', 'l ow', 'w est', 'n e']</code></li>
  <li><strong>Final vocabulary</strong>: <code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>, 256 byte chars, <code class="language-plaintext highlighter-rouge">st</code>, <code class="language-plaintext highlighter-rouge">est</code>, <code class="language-plaintext highlighter-rouge">ow</code>, <code class="language-plaintext highlighter-rouge">low</code>, <code class="language-plaintext highlighter-rouge">west</code>, <code class="language-plaintext highlighter-rouge">ne</code></li>
  <li><strong>â€œnewestâ€ tokenizes as</strong>: <code class="language-plaintext highlighter-rouge">['ne', 'west']</code></li>
</ul>

<h3 id="é¢„æœŸè¾“å‡º">é¢„æœŸè¾“å‡º</h3>

<p>é€šè¿‡6æ¬¡åˆå¹¶ï¼Œç®—æ³•äº§ç”Ÿï¼š</p>
<ul>
  <li><strong>åˆå¹¶</strong>ï¼š<code class="language-plaintext highlighter-rouge">['s t', 'e st', 'o w', 'l ow', 'w est', 'n e']</code></li>
  <li><strong>æœ€ç»ˆè¯æ±‡è¡¨</strong>ï¼š<code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>ã€256ä¸ªå­—èŠ‚å­—ç¬¦ã€<code class="language-plaintext highlighter-rouge">st</code>ã€<code class="language-plaintext highlighter-rouge">est</code>ã€<code class="language-plaintext highlighter-rouge">ow</code>ã€<code class="language-plaintext highlighter-rouge">low</code>ã€<code class="language-plaintext highlighter-rouge">west</code>ã€<code class="language-plaintext highlighter-rouge">ne</code></li>
  <li><strong>â€œnewestâ€è¢«åˆ†è¯ä¸º</strong>ï¼š<code class="language-plaintext highlighter-rouge">['ne', 'west']</code></li>
</ul>

<hr />

<p>Below is one implementation for Algorithm 1 of <a href="https://arxiv.org/abs/1508.07909">Sennrich et al. [2016]</a>.</p>

<p>ä¸‹é¢æ˜¯<a href="https://arxiv.org/abs/1508.07909">Sennrichç­‰äºº[2016]</a>çš„ç®—æ³•1çš„ä¸€ä¸ªå®ç°ã€‚</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Union</span>

<span class="k">class</span> <span class="nc">BPEEncoder</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Initialize vocabulary with special token and 256 byte values
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="s">"&lt;|endoftext|&gt;"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
        <span class="c1"># Add all possible byte values (0-255) to vocabulary
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">256</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">merges</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of (token1, token2) pairs that were merged
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">merge_tokens</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Maps (token1, token2) -&gt; new_token_id
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">token_names</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Maps token_id -&gt; readable name
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">next_token_id</span> <span class="o">=</span> <span class="mi">257</span>

    <span class="k">def</span> <span class="nf">pre_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="p">...],</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="s">"""
        Pre-tokenize text by splitting on whitespace and convert to byte tuples.
        Returns frequency count of each word as tuple of byte integers.
        For example, converts "low low low..." into {(l,o,w): 5, (l,o,w,e,r): 2, ...}
        """</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word_freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

        <span class="c1"># Convert to tuple of byte integers
</span>        <span class="n">byte_word_freq</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">byte_tuple</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">word</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
            <span class="n">byte_word_freq</span><span class="p">[</span><span class="n">byte_tuple</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq</span>

        <span class="k">return</span> <span class="n">byte_word_freq</span>

    <span class="k">def</span> <span class="nf">get_pair_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_freq</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="p">...],</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="s">"""
        Count frequency of all adjacent token pairs across all words.
        """</span>
        <span class="n">pair_freq</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">pair</span> <span class="o">=</span> <span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">pair_freq</span><span class="p">[</span><span class="n">pair</span><span class="p">]</span> <span class="o">+=</span> <span class="n">freq</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">merge_pair</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_freq</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="p">...],</span> <span class="nb">int</span><span class="p">],</span>
                   <span class="n">pair_to_merge</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
                   <span class="n">new_token</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="p">...],</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="s">"""
        Merge the specified pair in all words where it appears.
        """</span>
        <span class="n">new_word_freq</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="c1"># Check if current position matches the pair to merge
</span>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">pair_to_merge</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">pair_to_merge</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_token</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>  <span class="c1"># Skip both tokens of the pair
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">new_word_freq</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)]</span> <span class="o">=</span> <span class="n">freq</span>

        <span class="k">return</span> <span class="n">new_word_freq</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">num_merges</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="s">"""
        Train BPE on the given text for specified number of merges.
        Returns list of merge operations performed.
        """</span>
        <span class="c1"># Pre-tokenize text
</span>        <span class="n">word_freq</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pre_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial word frequencies: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">_format_word_freq</span><span class="p">(</span><span class="n">word_freq</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="n">merges_performed</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">merge_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_merges</span><span class="p">):</span>
            <span class="c1"># Get pair frequencies
</span>            <span class="n">pair_freq</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_pair_frequencies</span><span class="p">(</span><span class="n">word_freq</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">pair_freq</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="c1"># Find most frequent pair (lexicographically largest in case of tie)
</span>            <span class="n">max_freq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">.</span><span class="n">values</span><span class="p">())</span>
            <span class="n">most_frequent_pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">pair</span> <span class="k">for</span> <span class="n">pair</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">pair_freq</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">freq</span> <span class="o">==</span> <span class="n">max_freq</span><span class="p">]</span>

            <span class="c1"># Sort pairs lexicographically - convert to comparable format
</span>            <span class="k">def</span> <span class="nf">pair_sort_key</span><span class="p">(</span><span class="n">pair</span><span class="p">):</span>
                <span class="k">def</span> <span class="nf">token_to_str</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                        <span class="k">return</span> <span class="nb">chr</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

            <span class="c1"># Take lexicographically largest (max)
</span>            <span class="n">best_pair</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">most_frequent_pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">pair_sort_key</span><span class="p">)</span>

            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Merge </span><span class="si">{</span><span class="n">merge_step</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s">:"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Pair frequencies: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">_format_pair_freq</span><span class="p">(</span><span class="n">pair_freq</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Most frequent pair: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">_format_pair</span><span class="p">(</span><span class="n">best_pair</span><span class="p">)</span><span class="si">}</span><span class="s"> (freq: </span><span class="si">{</span><span class="n">max_freq</span><span class="si">}</span><span class="s">)"</span><span class="p">)</span>

            <span class="c1"># Create new token name
</span>            <span class="n">new_token</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"merge_</span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">next_token_id</span><span class="si">}</span><span class="s">"</span>

            <span class="c1"># Perform the merge
</span>            <span class="n">word_freq</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">merge_pair</span><span class="p">(</span><span class="n">word_freq</span><span class="p">,</span> <span class="n">best_pair</span><span class="p">,</span> <span class="n">new_token</span><span class="p">)</span>

            <span class="c1"># Record the merge
</span>            <span class="n">token1_name</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">token2_name</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">best_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">merge_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">token1_name</span><span class="si">}</span><span class="s"> </span><span class="si">{</span><span class="n">token2_name</span><span class="si">}</span><span class="s">"</span>
            <span class="n">merges_performed</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">merge_str</span><span class="p">)</span>

            <span class="c1"># Store merge information
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">merges</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_pair</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">merge_tokens</span><span class="p">[</span><span class="n">best_pair</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_token</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">new_token</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">next_token_id</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">token_names</span><span class="p">[</span><span class="n">new_token</span><span class="p">]</span> <span class="o">=</span> <span class="n">merge_str</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">next_token_id</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"After merge: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">_format_word_freq</span><span class="p">(</span><span class="n">word_freq</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">merges_performed</span>

    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="s">"""
        Tokenize a word using the learned BPE merges.
        """</span>
        <span class="c1"># Start with individual bytes as integers
</span>        <span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">word</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

        <span class="c1"># Apply merges in order
</span>        <span class="k">for</span> <span class="n">merge_pair</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">merges</span><span class="p">:</span>
            <span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span>
                    <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">merge_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">tokens</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">merge_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="c1"># Replace with the merged token name
</span>                    <span class="n">merged_token</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">merge_tokens</span><span class="p">[</span><span class="n">merge_pair</span><span class="p">]</span>
                    <span class="n">new_tokens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">merged_token</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_tokens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">new_tokens</span>

        <span class="c1"># Convert to readable format
</span>        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">chr</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">token</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'merge_'</span><span class="p">):</span>
                <span class="c1"># Convert back to the original characters this merge represents
</span>                <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">token_names</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_format_word_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_freq</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="p">...],</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Format word frequency dictionary for readable output."""</span>
        <span class="n">formatted</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">word_tuple</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">word_tuple</span><span class="p">]</span>
            <span class="n">word_str</span> <span class="o">=</span> <span class="s">'('</span> <span class="o">+</span> <span class="s">','</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s">')'</span>
            <span class="n">formatted</span><span class="p">[</span><span class="n">word_str</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">formatted</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_format_pair_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pair_freq</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Format pair frequency dictionary for readable output."""</span>
        <span class="n">formatted</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">pair</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="n">pair_freq</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">first</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">second</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pair_str</span> <span class="o">=</span> <span class="n">first</span> <span class="o">+</span> <span class="n">second</span>
            <span class="n">formatted</span><span class="p">[</span><span class="n">pair_str</span><span class="p">]</span> <span class="o">=</span> <span class="n">freq</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">formatted</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_format_pair</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pair</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Format a pair for readable output."""</span>
        <span class="n">first</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">second</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_token_to_str</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s">"(</span><span class="si">{</span><span class="n">first</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">second</span><span class="si">}</span><span class="s">)"</span>

    <span class="k">def</span> <span class="nf">_token_to_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="s">"""Convert a token to readable string."""</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">chr</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">token</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'merge_'</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">token_names</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">token</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

<span class="c1"># Example usage
</span><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="c1"># Initialize BPE encoder
</span>    <span class="n">bpe</span> <span class="o">=</span> <span class="n">BPEEncoder</span><span class="p">()</span>

    <span class="c1"># Example corpus
</span>    <span class="n">corpus</span> <span class="o">=</span> <span class="s">"low low low low low lower lower widest widest widest newest newest newest newest newest newest"</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"BPE Training on Corpus:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Corpus: </span><span class="si">{</span><span class="n">corpus</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

    <span class="c1"># Train with 6 merges
</span>    <span class="n">merges</span> <span class="o">=</span> <span class="n">bpe</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_merges</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Training Complete!"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Merges performed: </span><span class="si">{</span><span class="n">merges</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Test tokenization
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Tokenization Examples:"</span><span class="p">)</span>
    <span class="n">test_words</span> <span class="o">=</span> <span class="p">[</span><span class="s">"newest"</span><span class="p">,</span> <span class="s">"lower"</span><span class="p">,</span> <span class="s">"widest"</span><span class="p">,</span> <span class="s">"low"</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">test_words</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">bpe</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"'</span><span class="si">{</span><span class="n">word</span><span class="si">}</span><span class="s">' -&gt; </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Show final vocabulary (subset)
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"="</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"New Vocabulary (merged tokens only):"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="n">bpe</span><span class="p">.</span><span class="n">vocab</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">token</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'merge_'</span><span class="p">):</span>
            <span class="n">description</span> <span class="o">=</span> <span class="n">bpe</span><span class="p">.</span><span class="n">token_names</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Token ID </span><span class="si">{</span><span class="n">token_id</span><span class="si">}</span><span class="s">: '</span><span class="si">{</span><span class="n">description</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="sample-output">Sample Output</h2>

<p>When you run this code, youâ€™ll see output like:</p>

<h2 id="ç¤ºä¾‹è¾“å‡º">ç¤ºä¾‹è¾“å‡º</h2>

<p>å½“ä½ è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼çš„è¾“å‡ºï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    BPE Training on Corpus:
    Corpus: low low low low low lower lower widest widest widest newest newest newest newest newest newest
    ==================================================
    Initial word frequencies: {'(l,o,w)': 5, '(l,o,w,e,r)': 2, '(w,i,d,e,s,t)': 3, '(n,e,w,e,s,t)': 6}

    Merge 1:
    Pair frequencies: {'lo': 7, 'ow': 7, 'we': 8, 'er': 2, 'wi': 3, 'id': 3, 'de': 3, 'es': 9, 'st': 9, 'ne': 6, 'ew': 6}
    Most frequent pair: (s, t) (freq: 9)
    After merge: {'(l,o,w)': 5, '(l,o,w,e,r)': 2, '(w,i,d,e,s t)': 3, '(n,e,w,e,s t)': 6}

    Merge 2:
    Pair frequencies: {'lo': 7, 'ow': 7, 'we': 8, 'er': 2, 'wi': 3, 'id': 3, 'de': 3, 'es t': 9, 'ne': 6, 'ew': 6}
    Most frequent pair: (e, s t) (freq: 9)
    After merge: {'(l,o,w)': 5, '(l,o,w,e,r)': 2, '(w,i,d,e s t)': 3, '(n,e,w,e s t)': 6}

    Merge 3:
    Pair frequencies: {'lo': 7, 'ow': 7, 'we': 2, 'er': 2, 'wi': 3, 'id': 3, 'de s t': 3, 'ne': 6, 'ew': 6, 'we s t': 6}
    Most frequent pair: (o, w) (freq: 7)
    After merge: {'(l,o w)': 5, '(l,o w,e,r)': 2, '(w,i,d,e s t)': 3, '(n,e,w,e s t)': 6}

    Merge 4:
    Pair frequencies: {'lo w': 7, 'o we': 2, 'er': 2, 'wi': 3, 'id': 3, 'de s t': 3, 'ne': 6, 'ew': 6, 'we s t': 6}
    Most frequent pair: (l, o w) (freq: 7)
    After merge: {'(l o w)': 5, '(l o w,e,r)': 2, '(w,i,d,e s t)': 3, '(n,e,w,e s t)': 6}

    Merge 5:
    Pair frequencies: {'l o we': 2, 'er': 2, 'wi': 3, 'id': 3, 'de s t': 3, 'ne': 6, 'ew': 6, 'we s t': 6}
    Most frequent pair: (w, e s t) (freq: 6)
    After merge: {'(l o w)': 5, '(l o w,e,r)': 2, '(w,i,d,e s t)': 3, '(n,e,w e s t)': 6}

    Merge 6:
    Pair frequencies: {'l o we': 2, 'er': 2, 'wi': 3, 'id': 3, 'de s t': 3, 'ne': 6, 'ew e s t': 6}
    Most frequent pair: (n, e) (freq: 6)
    After merge: {'(l o w)': 5, '(l o w,e,r)': 2, '(w,i,d,e s t)': 3, '(n e,w e s t)': 6}

    ==================================================
    Training Complete!
    Merges performed: ['s t', 'e s t', 'o w', 'l o w', 'w e s t', 'n e']

    ==================================================
    Tokenization Examples:
    'newest' -&gt; ['n e', 'w e s t']
    'lower' -&gt; ['l o w', 'e', 'r']
    'widest' -&gt; ['w', 'i', 'd', 'e s t']
    'low' -&gt; ['l o w']

    ==================================================
    New Vocabulary (merged tokens only):
    Token ID 257: 's t'
    Token ID 258: 'e s t'
    Token ID 259: 'o w'
    Token ID 260: 'l o w'
    Token ID 261: 'w e s t'
    Token ID 262: 'n e'
</code></pre></div></div>

<hr />

<p>This implementation demonstrates how BPE learns to represent text efficiently by identifying and merging frequently occurring character patterns, creating a vocabulary that balances between the simplicity of byte-level tokenization and the efficiency of word-level tokenization.</p>

<p>è¿™ä¸ªå®ç°æ¼”ç¤ºäº†BPEå¦‚ä½•é€šè¿‡è¯†åˆ«å’Œåˆå¹¶é¢‘ç¹å‡ºç°çš„å­—ç¬¦æ¨¡å¼æ¥é«˜æ•ˆåœ°è¡¨ç¤ºæ–‡æœ¬ï¼Œåˆ›å»ºä¸€ä¸ªåœ¨å­—èŠ‚çº§åˆ†è¯çš„ç®€å•æ€§å’Œè¯çº§åˆ†è¯çš„æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡çš„è¯æ±‡è¡¨ã€‚</p>

  </div><a class="u-url" href="/chinese-online-content-for-llm/cs336/cs336-note-simple-bpe/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/chinese-online-content-for-llm/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/chinese-online-content-for-llm/feed.xml">
            <svg class="svg-icon orange"><use xlink:href="/chinese-online-content-for-llm/assets/minima-social-icons.svg#rss"></use></svg><span>Subscribe</span>
          </a>
        </p>
        <p>A curated collection of Chinese online content designed for Large Language Model training, evaluation, and research. Exploring high-quality Chinese language resources for multilingual AI development.
</p>
      </div>
      <div class="footer-col">
        <p>Â© 2025 ğŸ’ å¤§æ¨¡å‹æˆ‘éƒ½çˆ±</p>
      </div>
    </div>
  </div>

  <!-- Theme toggle button -->
  <button id="theme-toggle" aria-label="Toggle dark mode">ğŸŒ™</button>
</footer>
</body>

</html>
